<!DOCTYPE html>
<html lang="en-US">
<head>
		<!--[if lt IE 9]>
	<script src="https://www.dataquest.io/wp-content/themes/ignition/js/html5/dist/html5shiv.js"></script>
	<script src="//css3-mediaqueries-js.googlecode.com/svn/trunk/css3-mediaqueries.js"></script>
	<![endif]-->
	<!--[if IE 8]>
	<link rel="stylesheet" type="text/css" href="https://www.dataquest.io/wp-content/themes/ignition/css/ie8.css"/>
	<![endif]-->
	<!--[if IE 7]>
	<link rel="stylesheet" type="text/css" href="https://www.dataquest.io/wp-content/themes/ignition/css/ie7.css"/>
	<![endif]-->
	<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
	<meta charset="UTF-8">
	
			<link rel="stylesheet" href="https://use.typekit.net/nmj4kuc.css">


			<title>Tutorial: Learning Curves for Machine Learning in Python for Data Science</title>
<style type="text/css">.tve_more_tag {visibility: hidden; height: 1px!important;}</style>
<!-- This site is optimized with the Yoast SEO Premium plugin v12.4 - https://yoast.com/wordpress/plugins/seo/ -->
<meta name="description" content="This Python data science tutorial uses a real-world data set to teach you how to diagnose and reduce bias and variance in machine learning."/>
<meta name="robots" content="max-snippet:-1, max-image-preview:large, max-video-preview:-1"/>
<link rel="canonical" href="https://www.dataquest.io/blog/learning-curves-machine-learning/" />
<meta property="og:locale" content="en_US" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Tutorial: Learning Curves for Machine Learning in Python for Data Science" />
<meta property="og:description" content="This Python data science tutorial uses a real-world data set to teach you how to diagnose and reduce bias and variance in machine learning." />
<meta property="og:url" content="https://www.dataquest.io/blog/learning-curves-machine-learning/" />
<meta property="og:site_name" content="Dataquest" />
<meta property="article:publisher" content="https://www.facebook.com/dataquestio" />
<meta property="article:tag" content="advanced" />
<meta property="article:tag" content="bias" />
<meta property="article:tag" content="classification" />
<meta property="article:tag" content="curves" />
<meta property="article:tag" content="energy" />
<meta property="article:tag" content="Learn Python" />
<meta property="article:tag" content="learning curves" />
<meta property="article:tag" content="Machine Learning" />
<meta property="article:tag" content="power" />
<meta property="article:tag" content="python" />
<meta property="article:tag" content="Scikit-Learn" />
<meta property="article:tag" content="tutorial" />
<meta property="article:tag" content="Tutorials" />
<meta property="article:tag" content="variance" />
<meta property="article:section" content="Data Science Tutorials" />
<meta property="article:published_time" content="2018-01-03T15:55:54+00:00" />
<meta property="article:modified_time" content="2019-07-30T03:46:54+00:00" />
<meta property="og:updated_time" content="2019-07-30T03:46:54+00:00" />
<meta property="og:image" content="https://www.dataquest.io/wp-content/uploads/2019/01/topimage.jpeg" />
<meta property="og:image:secure_url" content="https://www.dataquest.io/wp-content/uploads/2019/01/topimage.jpeg" />
<meta property="og:image:width" content="1280" />
<meta property="og:image:height" content="852" />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:description" content="This Python data science tutorial uses a real-world data set to teach you how to diagnose and reduce bias and variance in machine learning." />
<meta name="twitter:title" content="Tutorial: Learning Curves for Machine Learning in Python for Data Science" />
<meta name="twitter:site" content="@dataquestio" />
<meta name="twitter:image" content="https://www.dataquest.io/wp-content/uploads/2019/01/topimage.jpeg" />
<meta name="twitter:creator" content="@dataquestio" />
<script type='application/ld+json' class='yoast-schema-graph yoast-schema-graph--main'>{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://www.dataquest.io/#organization","name":"Dataquest","url":"https://www.dataquest.io/","sameAs":["https://www.facebook.com/dataquestio","https://www.linkedin.com/company/dataquest-io","https://twitter.com/dataquestio"],"logo":{"@type":"ImageObject","@id":"https://www.dataquest.io/#logo","url":"https://www.dataquest.io/wp-content/uploads/2019/01/Logo-On-Light-BLUE.png","width":2001,"height":427,"caption":"Dataquest"},"image":{"@id":"https://www.dataquest.io/#logo"}},{"@type":"WebSite","@id":"https://www.dataquest.io/#website","url":"https://www.dataquest.io/","name":"Dataquest","publisher":{"@id":"https://www.dataquest.io/#organization"},"potentialAction":{"@type":"SearchAction","target":"https://www.dataquest.io/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://www.dataquest.io/blog/learning-curves-machine-learning/#primaryimage","url":"https://www.dataquest.io/wp-content/uploads/2019/01/topimage.jpeg","width":1280,"height":852,"caption":"python data science tutorial"},{"@type":"WebPage","@id":"https://www.dataquest.io/blog/learning-curves-machine-learning/#webpage","url":"https://www.dataquest.io/blog/learning-curves-machine-learning/","inLanguage":"en-US","name":"Tutorial: Learning Curves for Machine Learning in Python for Data Science","isPartOf":{"@id":"https://www.dataquest.io/#website"},"primaryImageOfPage":{"@id":"https://www.dataquest.io/blog/learning-curves-machine-learning/#primaryimage"},"datePublished":"2018-01-03T15:55:54+00:00","dateModified":"2019-07-30T03:46:54+00:00","description":"This Python data science tutorial uses a real-world data set to teach you how to diagnose and reduce bias and variance in machine learning."},{"@type":"Article","@id":"https://www.dataquest.io/blog/learning-curves-machine-learning/#article","isPartOf":{"@id":"https://www.dataquest.io/blog/learning-curves-machine-learning/#webpage"},"author":{"@id":"https://www.dataquest.io/#/schema/person/4c5e250c86fb00817deff723ed1d5e9a"},"headline":"Tutorial: Learning Curves for Machine Learning in Python","datePublished":"2018-01-03T15:55:54+00:00","dateModified":"2019-07-30T03:46:54+00:00","commentCount":0,"mainEntityOfPage":{"@id":"https://www.dataquest.io/blog/learning-curves-machine-learning/#webpage"},"publisher":{"@id":"https://www.dataquest.io/#organization"},"image":{"@id":"https://www.dataquest.io/blog/learning-curves-machine-learning/#primaryimage"},"keywords":"advanced,bias,classification,curves,energy,Learn Python,learning curves,Machine Learning,power,python,Scikit-Learn,tutorial,Tutorials,variance","articleSection":"Data Science Tutorials"},{"@type":["Person"],"@id":"https://www.dataquest.io/#/schema/person/4c5e250c86fb00817deff723ed1d5e9a","name":"Alex Olteanu","image":{"@type":"ImageObject","@id":"https://www.dataquest.io/#authorlogo","url":"https://www.dataquest.io/wp-content/uploads/2019/01/alex_olteanu_profile-1.jpg","caption":"Alex Olteanu"},"description":"Alex is a content author at Dataquest and writes courses on statistics and Python.","sameAs":[]}]}</script>
<!-- / Yoast SEO Premium plugin. -->

<link rel='dns-prefetch' href='//s.w.org' />
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/12.0.0-1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/12.0.0-1\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/www.dataquest.io\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.2.4"}};
			!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline="top",l.font="600 32px Arial",a){case"flag":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case"emoji":return b=d([55357,56424,55356,57342,8205,55358,56605,8205,55357,56424,55356,57340],[55357,56424,55356,57342,8203,55358,56605,8203,55357,56424,55356,57340]),!b}return!1}function f(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var g,h,i,j,k=b.createElement("canvas"),l=k.getContext&&k.getContext("2d");for(j=Array("flag","emoji"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],"flag"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",h,!1),a.addEventListener("load",h,!1)):(a.attachEvent("onload",h),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='wp-block-library-css'  href='https://www.dataquest.io/wp-includes/css/dist/block-library/style.min.css?ver=5.2.4' type='text/css' media='all' />
<link rel='stylesheet' id='searchandfilter-css'  href='https://www.dataquest.io/wp-content/plugins/search-filter/style.css?ver=1' type='text/css' media='all' />
<link rel='stylesheet' id='bodhi-svgs-attachment-css'  href='https://www.dataquest.io/wp-content/plugins/svg-support/css/svgs-attachment.css?ver=5.2.4' type='text/css' media='all' />
<link rel='stylesheet' id='tve_style_family_tve_flt-css'  href='https://www.dataquest.io/wp-content/plugins/thrive-visual-editor/editor/css/thrive_flat.css?ver=2.4.4.2' type='text/css' media='all' />
<link rel='stylesheet' id='l2h_style-css'  href='https://www.dataquest.io/wp-content/plugins/latex2html/inc/css/latex.min.css?ver=2.3.7' type='text/css' media='screen, print' />
<link rel='stylesheet' id='l2h_print_style-css'  href='https://www.dataquest.io/wp-content/plugins/latex2html/inc/css/print.min.css?ver=2.3.7' type='text/css' media='print' />
<link rel='stylesheet' id='ignition-style-css'  href='https://www.dataquest.io/wp-content/themes/ignition-child/style.css?ver=1.401.2.1550684985' type='text/css' media='all' />
<link rel='stylesheet' id='thrive-reset-css'  href='https://www.dataquest.io/wp-content/themes/ignition/css/reset.css' type='text/css' media='all' />
<link rel='stylesheet' id='thrive-main-style-css'  href='https://www.dataquest.io/wp-content/themes/ignition/css/main_navy.css?ver=2014123' type='text/css' media='all' />
<link rel='stylesheet' id='chld_thm_cfg_separate-css'  href='https://www.dataquest.io/wp-content/themes/ignition-child/ctc-style.css?ver=1.401.2.1550684985' type='text/css' media='all' />
<link rel='stylesheet' id='thrive-apprentice-style-css'  href='https://www.dataquest.io/wp-content/themes/ignition/appr/css/apprentice_green.css?ver=20120208' type='text/css' media='all' />
<link rel='stylesheet' id='jquery-data-tables-css'  href='https://www.dataquest.io/wp-content/plugins/posts-data-table/assets/js/datatables/datatables.min.css?ver=1.10.18' type='text/css' media='all' />
<link rel='stylesheet' id='posts-data-table-css'  href='https://www.dataquest.io/wp-content/plugins/posts-data-table/assets/css/posts-data-table.min.css?ver=1.2' type='text/css' media='all' />
<link rel='stylesheet' id='prism-theme-css'  href='https://www.dataquest.io/wp-content/plugins/ank-prism-for-wp/out/prism-css.min.css?ver=1550607458' type='text/css' media='all' />
<script type='text/javascript'>
/* <![CDATA[ */
var THO_Head = {"variations":[],"post_id":"1998","element_tag":"thrive_headline","woo_tag":"tho_woo"};
/* ]]> */
</script>
<script type='text/javascript' src='https://www.dataquest.io/wp-content/plugins/thrive-headline-optimizer/frontend/js/header.min.js?ver=1.1.30'></script>
<script type='text/javascript' src='https://www.dataquest.io/wp-includes/js/jquery/jquery.js'></script>
<script type='text/javascript' src='https://www.dataquest.io/wp-includes/js/jquery/jquery-migrate.min.js'></script>
<link rel='https://api.w.org/' href='https://www.dataquest.io/wp-json/' />
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://www.dataquest.io/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://www.dataquest.io/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 5.2.4" />
<link rel='shortlink' href='https://www.dataquest.io/?p=1998' />
<link rel="alternate" type="application/json+oembed" href="https://www.dataquest.io/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fwww.dataquest.io%2Fblog%2Flearning-curves-machine-learning%2F" />
<link rel="alternate" type="text/xml+oembed" href="https://www.dataquest.io/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fwww.dataquest.io%2Fblog%2Flearning-curves-machine-learning%2F&#038;format=xml" />
<style type="text/css" id="tve_global_variables">:root{--tcb-color-0:rgb(35, 42, 61);--tcb-color-1:rgb(132, 132, 157);--tcb-color-2:rgb(77, 127, 223);--tcb-color-3:rgb(97, 209, 153);--tcb-color-4:rgb(0, 0, 0);--tcb-color-5:rgb(0, 0, 0);--tcb-color-6:rgb(0, 0, 0);--tcb-color-7:rgb(212, 212, 212);--tcb-color-8:rgb(137, 138, 142);--tcb-color-9:rgb(242, 243, 247);--tcb-color-10:rgba(35, 42, 61, 0.77);--tcb-color-11:rgb(97, 209, 153);--tcb-color-12:rgb(255, 255, 255);--tcb-color-13:rgb(35, 42, 61);--tcb-gradient-0:linear-gradient(90deg, rgb(97, 209, 153) 0%, rgb(78, 126, 222) 98%);}</style>	<script>
		/************* Helper functions ******************/
		function isInArray(value, array) {
		  return array.indexOf(value) > -1;
		}
		function getHostFromUrl(url) {
			var a=document.createElement('a');
			a.href=url;
			return a.hostname;
		}
		function getUrlVar(key){
			var result = new RegExp(key + "=([^&]*)", "i").exec(window.location.search); 
			return result && unescape(result[1]) || ""; 
		}
		/************* End of Helper Functions ******************/
		
		
		/******************** Cookie helper functions ************************/
		function checkCookieExists(cookie_name) {
			return document.cookie.indexOf(cookie_name + '=') !== -1;
		}
		function setCookie(name,value,domain,days) {
			var expires = "";
			if (days) {
				var date = new Date();
				date.setTime(date.getTime() + (days*24*60*60*1000));
				expires = "; expires=" + date.toUTCString();
			}
			document.cookie = name + "=" + (value || "")  + expires +  ";domain=" + domain + "; path=/";
		}
		/******************** End Of Cookie helper functions ******************/
		
		function setRefererUrlCookie() {
			var cookie_domain = '.dataquest.io'
			var internal_hosts =  ['www.dataquest.io', 'dataquest.io', ]

			/* Set Landing page cookie if it doesnot exist */
			if (!checkCookieExists('dataquest-cac-landing-page')) {
				setCookie('dataquest-cac-landing-page', window.location.pathname, cookie_domain, 7)
			}
			
			var referrer = document.referrer
			if (!referrer) {
				return
			}
			host = getHostFromUrl(referrer)
			
			/* If referrer is not coming from dataquest, set it in cookie and override landing_page cookie */
			if (!isInArray(host, internal_hosts)) {
				setCookie('dataquest-cac-referer-url', referrer, cookie_domain, 365)
				setCookie('dataquest-cac-landing-page', window.location.pathname, cookie_domain, 365)
			}
		}

		function setUTMCodesCookies() {
			var utm_codes = ['utm_source','utm_campaign','utm_content','utm_term','utm_medium']
			var cookie_prefix = 'dataquest-cac-'
			var cookie_domain = '.dataquest.io'
			
			for (code in utm_codes) {
				var utm_code = utm_codes[code]
				var code_value = getUrlVar(utm_code)
				var cookie_name = cookie_prefix + utm_code.replace('_', '-')
				
				if (code_value) {
					setCookie(cookie_name, code_value, cookie_domain, 365)
				}
			}
		}
									
		
		function setLandingPageLastTouchCookie() {
			var cookie_domain = '.dataquest.io'
			setCookie('dataquest-cac-landing-page-last-touch', window.location.pathname, cookie_domain, 365)

		}
		
		setUTMCodesCookies()
		setRefererUrlCookie()
		setLandingPageLastTouchCookie()

	</script>
<style>
.latex_thm, .latex_lem, .latex_cor, .latex_defn, .latex_prop, .latex_rem{
  margin:0;padding:5px;
  background: lightcyan;
  border: solid 3px green;
  -moz-border-radius: 1.0em;
  -webkit-border-radius: 7px;
  box-shadow: 0 0 0 green;
}
.latex_em{
  font-style: italic;
}
.bibtex_title{
  font-weight:bold;
  color: #004b33;
}
a.bibtex_title{
  text-decoration: none;
}
.latex_proof::after{
  content: "\220E";
  color: gray;
  text-align: right;
  display: block;
  font-size: 1.2em;
}
</style>
		<style type="text/css">body { background:#ffffff; }.cnt article h1.entry-title a { color:#0a0a0a; }.cnt article h2.entry-title a { color:#0a0a0a; }.bSe h1 { color:#0a0a0a; }.bSe h2 { color:#0a0a0a; }.bSe h3 { color:#0a0a0a; }.bSe h4 { color:#0a0a0a; }.bSe h5 { color:#0a0a0a; }.bSe h6 { color:#0a0a0a; }.cnt article p { color:#0a0a0a; }.cnt .bSe article { color:#0a0a0a; }.cnt article h1 a, .tve-woocommerce .bSe .awr .entry-title, .tve-woocommerce .bSe .awr .page-title{font-family:Open Sans,sans-serif;}.bSe h1{font-family:Open Sans,sans-serif;}.bSe h2,.tve-woocommerce .bSe h2{font-family:Open Sans,sans-serif;}.bSe h3,.tve-woocommerce .bSe h3{font-family:Open Sans,sans-serif;}.bSe h4{font-family:Open Sans,sans-serif;}.bSe h5{font-family:Open Sans,sans-serif;}.bSe h6{font-family:Open Sans,sans-serif;}.cnt, .bp-t, .tve-woocommerce .product p, .tve-woocommerce .products p{font-family:Open Sans,sans-serif;font-weight:400;}article strong {font-weight: bold;}.bSe h1, .bSe .entry-title { font-size:36px; }.cnt { font-size:14px; }.out { font-size:14px; }.thrivecb { font-size:14px; }.aut p { font-size:14px; }.cnt p { line-height:2em; }.lhgh { line-height:2em; }.dhgh { line-height:2em; }.dhgh { font-size:14px; }.lhgh { font-size:14px; }.thrivecb { line-height:2em; }.cnt .cmt, .cnt .acm { background-color:#4d7fdf; }.trg { border-color:#4d7fdf transparent transparent; }.str { border-color: transparent #4d7fdf transparent transparent; }.brd ul li { color:#4d7fdf; }.bSe a { color:#4d7fdf; }.bSe .faq h4{font-family:Open Sans,sans-serif;font-weight:400;}article strong {font-weight: bold;}header ul.menu > li > a { color:#ffffff; }header .phone .apnr, header .phone .apnr:before, header .phone .fphr { color:#ffffff; }header ul.menu > li > a:hover { color:#ffffff; }header .phone:hover .apnr, header .phone:hover .apnr:before, header .phone:hover .fphr { color:#ffffff; }header nav > ul > li.current_page_item > a:hover { color:#ffffff; }header nav > ul > li.current_menu_item > a:hover { color:#ffffff; }header nav > ul > li.current_menu_item > a:hover { color:#ffffff; }header nav > ul > li > a:active { color:#ffffff; }header #logo > a > img { max-width:180px; }header ul.menu > li.h-cta > a { color:#FFFFFF!important; }header ul.menu > li.h-cta >a  { background:#ffffff; }header ul.menu > li.h-cta > a { border-color:#ffffff; }header ul.menu > li.h-cta > a:hover { color:#FFFFFF!important; }header ul.menu > li.h-cta > a:hover { background:#ffffff; }.product.woocommerce.add_to_cart_inline a.button.product_type_simple.ajax_add_to_cart { background-color:#FFFFFF; }.product.woocommerce.add_to_cart_inline a.button.product_type_simple.ajax_add_to_cart { border-color:#4d7fdf; }.product.woocommerce.add_to_cart_inline a.button.product_type_simple.ajax_add_to_cart { color:#4d7fdf; }.product.woocommerce.add_to_cart_inline a.button.product_type_simple.ajax_add_to_cart:hover { background-color:#4d7fdf; }.woocommerce p.return-to-shop a.button.wc-backward { border-color:#4d7fdf; }.woocommerce p.return-to-shop a.button.wc-backward { color:#4d7fdf; }.woocommerce p.return-to-shop a.button.wc-backward:hover { background:#4d7fdf; }.woocommerce p.return-to-shop a.button.wc-backward:hover { color:#FFFFFF; }</style>
		<style type="text/css" id="custom-background-css">
body.custom-background { background-color: #ffffff; }
</style>
	<link rel="icon" href="https://www.dataquest.io/wp-content/uploads/2019/01/cropped-rocket-icon-50x50.jpg" sizes="32x32" />
<link rel="icon" href="https://www.dataquest.io/wp-content/uploads/2019/01/cropped-rocket-icon-300x300.jpg" sizes="192x192" />
<link rel="apple-touch-icon-precomposed" href="https://www.dataquest.io/wp-content/uploads/2019/01/cropped-rocket-icon-300x300.jpg" />
<meta name="msapplication-TileImage" content="https://www.dataquest.io/wp-content/uploads/2019/01/cropped-rocket-icon-300x300.jpg" />
<style type="text/css" class="tve_global_style"></style>			<style type="text/css"
				   class="tve_custom_style">@import url("//fonts.googleapis.com/css?family=Lato:400,700,300,&subset=latin");@media (min-width: 300px){[data-css="tve-u-16aa32f01a5"] p { margin: 0px !important; padding: 0px !important; }[data-css="tve-u-16aa32f01a5"] h1 { margin: 0px !important; padding: 0px !important; }:not(#tve) [data-css="tve-u-16aa32f01a7"]:hover .tcb-button-link { background-image: none !important; background-color: rgb(88, 177, 127) !important; }[data-css="tve-u-16aa32f01a7"] strong { font-weight: 700; }[data-css="tve-u-16aa32f01a7"] { display: block; max-width: 250px; margin-bottom: -42px !important; }:not(#tve) [data-css="tve-u-16aa32f01a7"] .tcb-button-link { font-size: 30px; font-family: Lato; font-weight: 400; }[data-css="tve-u-16aa32f01a7"] .tcb-button-link { border: 2px solid rgb(77, 127, 223); background-image: none !important; background-color: rgb(97, 209, 153) !important; padding: 20px !important; }:not(#tve) [data-css="tve-u-16aa32f01a8"] { font-size: 18px !important; color: rgb(35, 44, 61) !important; font-family: inherit !important; }[data-css="tve-u-16aa32f01aa"] { background-image: none !important; margin-top: 0px !important; margin-bottom: 60px !important; }[data-css="tve-u-16aa32f01a5"] { min-height: 97px; }[data-css="tve-u-16aa32f01ab"] { background-image: none !important; background-color: rgb(255, 255, 255) !important; border: 2px solid rgb(77, 127, 223)  !important; }[data-css="tve-u-16aa32f01ac"] { padding: 43px 43px 10px !important; margin-top: 40px !important; margin-bottom: 80px !important; }[data-css="tve-u-16aa32f01ad"] { background-image: none !important; margin-top: -48px !important; padding-bottom: 0px !important; margin-bottom: 30px !important; }:not(#tve) [data-css="tve-u-16aa32f01af"] { font-size: 42px !important; color: rgb(97, 209, 153)  !important; }}@media (max-width: 767px){[data-css="tve-u-16aa32f01ad"] { background-image: none !important; }}</style>		<style type="text/css" id="wp-custom-css">
			body  {font-family: ingra, sans-serif; color: #232a3d;}

button, input, select, textarea, h4, h5, h6, .widget-area.sidebar, nav, p, .thrv-styled-list-item, .bSe h4, ol li, ul li  {font-family: ingra, sans-serif; font-weight: 300; color: #232a3d; }

.single-post article, .single-post article ul li, .single-post article p, .single-post article blockquote, .single-post article ol li {line-height: 1.8em; font-size: 15px; font-family: merriweather;}

.page-template-fullwidth-page p, .page-template-default p, .page-template-default ul li, .page-template-default ol li {font-family: ingra, sans-serif; line-height: 1.7em; margin: 0px 0px; font-size: 16px; color: #232a3d!important; font-weight: 300;}

.tcb-button-text {font-family: industry, sans-serif!important; font-weight: 700; letter-spacing: 1px;}

h1, h2, h3 {font-family: industry, sans-serif!important; color: #232a3d!important; font-weight: 700!important;}

.bSe h1 {font-size: 36px!important;}

.scn>ul a:hover, section[id*='nav_menu-'] .scn ul a:hover, .scn ul[id*='menu'] a:hover {margin: 0px;}

.path-box h3 {font-size: 17px!important; font-weight: 900; margin: 0px 0px 5px 0px; line-height: 1em}

.path-box p {line-height: 1.6em; font-size: 14px;}

.path-box a {text-decoration: none!important;}

.path-box-button-text {text-transform: uppercase!important; letter-spacing: 1px;}


.post-template-default h1, .post-template-default h2, .post-template-default h3 {padding: 40px 0px 20px}

.post-template-default h4, .post-template-default h5, .post-template-default h6 {padding: 10px 0px 20px}


#floating_menu header {padding: 2px;}



.menu, .page_item a, .menu-item a {font-size: 11px; text-transform: UPPERCASE; text-decoration: none; font-weight: 100; line-height: 1em;}

header #logo > a > img {padding: 10px 0px 10px 0px;}

header nav>ul>li.menu-item-has-children:hover>a:after, 
header nav>ul>li.menu-item-has-children>a:after {color: #ffffff!important; font-weight: 100; }

header nav>ul.menu li.current-menu-item>a, header nav>ul.menu li.current_page_item>a, header nav ul#menu li.current-menu-item>a, header nav ul#menu li.current_page_item>a {color: #ffffff;}

header nav li.col-no-4>ul.sub-menu, header nav li.col-no-4 ul.sub-menu.position_menu {margin-top: 20px;}

header nav>ul>li.menu-item-has-children>a:after {display: none;}

header nav li.has-extended>ul.sub-menu {background: #ffffff;}

header nav li.has-extended>ul.sub-menu li.menu-item {background: transparent; }

header nav li.has-extended>ul.sub-menu li.menu-item a[href] {color: #232a3d;}

header nav li.has-extended>ul.sub-menu li.menu-item a[href]:hover {color: #4d7fdf; background-color: rgb(242, 243, 247);}

#menu-item-11096 a.colch {padding: 18px 8px 8px 8px; font-size: 14px; font-weight: 900;}

#menu-item-11069 a.colch, #menu-item-11053 a.colch, #menu-item-11054 a.colch {color: #ffffff;}
 

li.has-extended>ul.sub-menu>li ul.sub-menu li {margin: 0px 0px 0px 0px;}

header nav li.has-extended>ul.sub-menu>li ul.sub-menu li a {line-height: 1.6em; padding: 10px 0px 10px 10px; font-size: 12px;}

@media only screen and (max-width: 769px) {
	header .hmn .rmn {background-image: none; border: 0px;}
}

@media only screen and (min-width: 769px) {
	#menu-item-20221 a {background-color: #61D199; border-radius: 5px;  padding: 6px 8px 5px; margin-top: -6px;}}

@media only screen and (max-width: 768px) {
	header nav li.has-extended ul.sub-menu li a {display: none;} 

li#menu-item-11094	ul.sub-menu {display: none!important;}
}


.csbwfs-social-widget {
    z-index: 100!important;
}

.page-template-default .csbwfs-social-widget, .blog .csbwfs-social-widget {display: none;}

:not(pre) > code[class*="language-"], pre[class*="language-"] {background-color: #000000; border-radius: 3px;}

p code {
background-color: #e5eff5;
padding: 1px 3px;
border-radius: 3px;
font-size: .95em;
color: #000000;}

pre {background: #000000; margin-top: -10px;}
pre code {font-size: 13px; padding: 0px; color: #ffffff; background: #000000;}

code[class*="language-"], pre[class*="language-"] {font-size: 15px; margin-bottom: 20px; margin-top: -10px;}



.single-post table {width: 85%; margin: 30px auto; }

.single-post table th {background-color: #f4f8fb; /*text-transform: lowercase;*/ color: #232a3d!important;}

.single-post table td, article table th {font-size: 15px; border: 1px solid #e3ecf3; font-family: ingra, sans-serif; }

.single-post h1, .single-post h2, .single-post h3, .single-post h4, .single-post h5 {font-family: merriweather!important;}

.single-post .bSe h1.entry-title {font-size: 38px!important; color: #232a3d!important;}
.single-post h2 {font-size: 32px; color: #232a3d!important;}
.single-post h3 {font-size: 29px; color: #232a3d!important;}
.single-post h4 {font-size: 26px; color: #232a3d!important;}
.single-post h5 {font-size: 23px; color: #232a3d!important;}

.page-header .page-title {text-transform: none; color: #ffffff; font-weight: normal; letter-spacing: 0em; font-size: 18px; line-height: 24px;}


.widgets-list-layout-links  {line-height: 1.3; font-size: 14px}


.sidebar .widget .widget-title {font-family: ingra, sans-serif; letter-spacing: 1.5px; padding-bottom: 15px; border-top: 1px solid #e9e9e9!important; padding-top: 25px;}

.site-branding .site-title, .site-branding .site-text-logo {font-size: 20px; color: #ffffff; font-weight: normal; text-transform: none;}

#content img {display: block; margin: 0px auto;}

div table{
    overflow-x:auto;
}

.scn ul li a {color: #232a3d;}
.scn ul li a:hover {color: #4d7fdf;}


.err {text-align: center;}
.err h1 {display: none;}
.err h4 {display: none;}
form.lost {
	display: inline-block; width: 80%;}

.err .csc {text-align: left;}


.sAs .srh input.search-field, .sAs .srh .search_field {
	width: 285px;}

 .srh input.search-field,  .srh .search_field {background-color: #ffffff; box-shadow: none; border-top: 2px solid #31394a; border-left: 2px solid #31394a; border-bottom: 2px solid #31394a; border-right: 0px;}

input.search-field {font-size: 13px; line-height: 15px; padding: 10px;}

input.search-field::-webkit-input-placeholder { 
  color: transparent;
}
input.search-field::-moz-placeholder {
  color: transparent;
}
input.search-field:-ms-input-placeholder { /* IE 10+ */
  color: transparent;
}
	
input.search-field:-moz-placeholder {
  color: transparent;
}

form.srh {margin-left: 0px; padding-top: 5px; }

input.search-field, .search_field {font-size: 1em; font-weight: 100; }

input.search-field, .search-button, .submit_btn {
    height: 40px; margin: 0px; padding: 0px 0px 0px 5px;
	}

.search-button, .submit_btn {background-color: #31394a!important; background-image:none; border: none; height: 47px!important;}

.sAs .search-button, .sAs .submit_btn { 
    width: 50px; z-index: 1000; position: relative;  top: -47px; left: 292px; }

@media only screen and (max-width: 1080px) {
.sAs .search-button, .sAs .submit_btn { 
	width: 50px; z-index: 1000; position: relative;  top: -0px; left: 0px; }
	form.srh {margin-bottom: 20px;}
	
	.sAs .srh input.search-field, .sAs .srh .search_field {
    height: 43px;
}
}


svg.tcb-icon {
	color: #61d199; 
}

.gmt-edd-slack-row {
	text-align: center;
}

input#gmt_edd_slack_email {
  width: 280px;
	text-align: left;
	padding: 10px 30px 10px 15px; 
}

button.gmt-edd-slack-form-button {
font-size: 16px; line-height: 15px; padding: 14px 30px; background-color: #61D199; color: #ffffff;  margin: 5px 10px; border: 0px; border-radius: 3px; text-transform: uppercase; width: 250px;
}

.thrv_wrapper.thrv-pricing-table .tcb-pricing-table-box-container .tcb-pt-featured-box .tve-content-box-background {
    border-top-color: #61d199;
}


.tvo-set12-template.tve_teal .tvo-testimonial-quote {color: #4d7fdf!important;}

.tvo-set12-template.tve_teal .tvo-testimonial-name {color: #4d7fdf!important;}


.directory-coursebox p {margin-top: 0px; font-size: 14px; margin-bottom: 22px!important; }

.directory-coursebox .tcb--cols--2 {margin-top: 5px;}

.directory-course-label p {margin: 3px 0px; }

a .thrv-content-box p {color: #ffffff!important; text-decoration: none!important;}

@media only screen and (max-width: 769px) {
	.directory-coursebox .tcb--cols--2, .directory-coursebox .tcb--cols--2 p { text-align: center!important; }}

@media only screen and (max-width: 769px) {
	.directory-coursebox .tcb--cols--2 .directory-course-label p { margin-top: -20px;}}

@media only screen and (max-width: 769px) {
	.directory-coursebox .tcb--cols--2 .thrv-button a { margin-top: -20px;}}

.directory-coursebox .tcb-button-texts {padding: 0px 20px;}

@media only screen and (max-width: 767px){.thrv_wrapper.thrv-columns.directory-course-columns {margin-top: -40px;}}

.path-box-button-text p {font-family: industry!important; font-weight: 700;}

.course-box-course-info p {font-family: industry!important; font-weight: 700; font-size: 14px}

.course-box h2 {font-size: 22px;}

.course-box p {font-size: 13px;}

.course-box a {text-decoration: none!important;}

.scn.aut {
    box-shadow: none;
    background: #ffffff;
    border-radius: 5px;
    border: 2px solid #d4d4d4;
    margin-bottom: 10px;
}

.scn h5 {font-family: industry, sans-serif; font-weight: 900;}

.blog .awr h2.entry-title, .archive .awr h2.entry-title, .search .awr h2.entry-title  { font-size: 24px!important; font-weight: 900; line-height: 1.4em!important; margin-top: 10px; margin-bottom: 10px; font-family: ingra, serif!important; text-align: left;}
.cnt article h2.entry-title a {color: #232a3d!important;}

.cnt article h2.entry-title a:hover {color: #4d7fdf!important;}

.blog .awr .category a, .archive .awr .category a, .search .awr .category a {font-family: ingra, sans-serif; text-decoration: none; font-size: 13px; text-transform: uppercase; letter-spacing: 1px; font-weight: 300; line-height: 2em; }

.blog .awr p, .archive .awr p, .search .awr p {font-family: merriweather, serif!important; margin-bottom: 0px!important; line-height: 1.9em; color: #232a3d!important;}

.blog footer, .archive footer, .search footer  {margin: 5px!important;}




.cnt .rltp p, .cnt .rltp h5, .cnt .rltpi a p, .cnt .rltpi h5  {font-family: ingra, sans-serif;  font-weight: 500; font-size: 15px; color: #232a3d; }



.cnt .rltp p:before, .cnt .rltpi p:before {display: none;}

.cnt .rltp h5, .cnt .rltpi h5 {margin: 5px 0px;}

.cnt article ul {
    list-style: disc;
}



.cnt section footer {}



footer .ftw {background-color: #232a3d; padding: 40px 0px 0px 0px;}

footer .ftw ul li a, footer .ftw .textwidget  {color: #ffffff;  font-size: 12px;}

footer .copy {display: none;}

.tvo-set12-template.tvo-testimonials-display-single .tvo-testimonial-quote {font-family: industry!important; font-size: 168px!important; margin-left: -10px;}

.tvo-testimonials-display.tvo-set12-template .tvo-testimonial-display-item h4, .tvo-testimonials-display.tvo-set12-template .tvo-testimonial-display-item p {font-family: ingra!important;  font-size: 15px!important; font-weight: 100!important; font-style: normal!important; color: #0C0A48!important;}



.tvo-testimonial-info svg {display: none; }

.tvo-testimonial-info .tvo-testimonial-name, .tvo-testimonial-info .tvo-testimonial-role {
font-family: ingra!important;  font-size: 15px!important;
color: #232a3d!important;}

.tvo-testimonial-info .tvo-testimonial-name {font-weight: 700!important;;}



.tvo-set12-template.tvo-testimonials-display-single .tvo-testimonial-quote:before, .tvo-set12-template.tvo-testimonials-display-single .tvo-testimonial-quote:after {display: none;}

@media only screen and (min-width: 768px) {
	.why-p, .mission-two-columns {column-count: 2; column-gap: 40px; }}

.why-p p, .why-p ul li {font-size: 15px; margin-bottom: 20px!important; font-weight: 300;}

.gmt-edd-slack-alert-success {border: 1px solid #000000; padding: 20px; text-align: center;}

.sub-picker .tve_scT .tve_scTC {background: transparent; border: 0px;}

.sub-picker .tve_scT>ul li {border: 1px solid #cccccc; text-transform: capitalize; }

.sub-picker .tve_scT>ul li.annual {border-radius: 5px;}

.sub-picker .tve_scT>ul li.monthly {border-radius: 5px; margin-bottom: 5px!important;}

.thrv_wrapper.thrv-tabbed-content div.tve_scT>ul li span {width: 70px; font-size: 12px; font-family: industry; letter-spacing: 1px; line-height: 1em; }

.sub-picker ul.mon-ann {display: block; margin: auto auto!important; width: 200px; }

.sub-picker ul li.annual, .sub-picker ul li.monthly {padding: 10px!important; }

.thrv-pricing-table {margin-top: -40px}

.thrv_wrapper.thrv-tabbed-content div.tve_scT>ul li:hover {color: #232a3d; }

.main-testimonial .tvo-testimonials-display.tvo-set12-template .tvo-testimonial-display-item p {font-size: 20px!important;}

.mission-ppp-horizontal {display: none;}

.mission-outline p {font-size: 14px;  line-height: 1.6em; padding-top: 8px;}

.mission-outline br {line-height: 3em}

.mission-outline {column-count: 1; column-gap: 10px; }

.ctb {border: none;}
.ctb h5  {display: none;}

#comments {border: none;}

.cmc {margin: 0 auto 20px auto; }
.cmc .awe {display: none;}
.cmc, .cmc p {font-family: ingra!important; color: #232a3d!important; }

.cmb {margin: 0px;}

.lrp p {font-family: industry, sans-serif!important; font-size: 18px!important; color: #232a3d!important;}

textarea:not(.editor-post-title__input) {background: #ffffff; box-shadow: none; border: 2px solid #e9e9e9; }

.lrp input[type="submit"] {
    background: #61D199;
    border-radius: 5px;
	border: 0px;
    color: #ffffff;
    font-size: 1em;
    font-family: industry, sans-serif;
    margin: 20px 0;
    padding: 12px 36px 12px 36px;
    text-align: center;
}

.lrp input[type="text"] {
    box-sizing: border;
    border-radius: 5px;
	box-shadow: none;
    background: #ffffff;
    border: 1px solid #e9e9e9;
    color: #232a3d;
    float: left;
    font-size: 1em;
    font-weight: 700;
    font-family: ingra, sans-serif;
    height: 32px;
    margin: 0% 4.2% 3% 0%;
    padding: 0% 0% 0% 2%;
    width: 30.3%;
}

.lrp textarea::-webkit-input-placeholder {
   color:transparent;
}

.lrp textarea:-moz-placeholder { /* Firefox 18- */
   color:transparent; 
}

.lrp textarea::-moz-placeholder {  /* Firefox 19+ */
   color:transparent; 
}

.lrp textarea:-ms-input-placeholder {  
   color:transparent;
}

.footer-links a {color: #ffffff; line-height: 2}


#tve_tcb2_set-021 {display: none;}

a.tcb-button-link {background-color: #61D199; text-transform: uppercase; padding: 12px 30px; border-radius: 5px!important;}

a.tcb-button-link:hover {background-color: rgb(97, 209, 153) !important; }


.industry p {font-family: industry, sans-serif!important; }

body.home {background-color: #232a3d;}

.course-header p strong, .mission-header p strong, .mission-header .tcb-plain-text {font-size: 12px!important; letter-spacing: 3px;
    color: rgb(77, 127, 223) !important;}

.mission-header .tcb-plain-text {margin-bottom: 10px;}

.directory-coursebox h3 {margin-top: 5px}

.post-template-default .sidebar-blog-title h2 {font-family: industry!important; margin-top: -10px; margin-bottom: 0px;}

.post-template-default .sidebar-blog-subtitle { margin-bottom: 20px;}

#signup_form .error {
    display: block;
    line-height: .7em;
    padding: 0;
    color: #a94342;
    font-family: ingra,sans-serif;
    font-weight: 400;
	border: 1px solid #990000;
}


.cnt .sAs .ttl {font-family: industry; color: #31394a; border: 0px; margin-bottom: 0px; font-size: 22px; margin-left: 5px;}

section[id*='nav_menu-'] .scn ul li, .scn ul[id*='menu'] li {border-bottom: 0px; padding: 10px 0px; list-style-type: disc; margin-left: 40px; color: #31394a; font-family: ingra; letter-spacing: 1px;}

.scn ul li a {font-size: 13px;}

.scn>ul li:after, section[id*='nav_menu-'] .scn ul li:after, .scn ul[id*='menu'] li:after {content: none; }


.cnt .sAs>section {margin-bottom: 20px!important;}

#nav_menu-3 {margin-top: -20px;}

.cnt .sAs.right {border: 0px;}

.tve_flt .tve_contents_table .tve_ct_title {font-family: industry; text-align: left; display: block; margin: 0px ; padding: 0px 0px 10px; font-weight: bold; font-size: 24px;}

blockquote {
	padding: 20px;
	color: #428bca;
	border-left: 5px solid #428bca;
}

.sidebar-blog-title h2 {margin: 0px; padding: 10px}
		</style>
					</head>
<body class="post-template-default single single-post postid-1998 single-format-standard custom-background locale-en-us">

<div class="flex-cnt">
	<div id="floating_menu" >
				<header class="hbc" style="background-image:none; background-color:#232a3d">
						<div class="wrp side_logo clearfix has_phone" id="head_wrp">
				<div class="h-i">
																	<div id="logo"
							     class="left">
								<a class="lg" href="https://www.dataquest.io/">
									<noscript><img src="https://www.dataquest.io/wp-content/uploads/2019/01/dq-1.png"
									     alt="Dataquest"/></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="https://www.dataquest.io/wp-content/uploads/2019/01/dq-1.png"
									     alt="Dataquest"/>
								</a>
							</div>
																						<div class="hmn">
							<div class="awe rmn right">&#xf0c9;</div>
							<div class="clear"></div>
						</div>
						<div class="mhl" id="nav_right">
																													<!-- Cart Dropdown -->
								<nav class="right"><ul id="menu-primary" class="menu"><li  id="menu-item-20226" class="menu-item menu-item-type-post_type menu-item-object-page"><a  href="https://www.dataquest.io/directory/">Courses</a></li>
<li  id="menu-item-20223" class="menu-item menu-item-type-taxonomy menu-item-object-category"><a  href="https://www.dataquest.io/blog/topics/student-stories/">Student Stories</a></li>
<li  id="menu-item-20225" class="menu-item menu-item-type-post_type menu-item-object-page"><a  href="https://www.dataquest.io/were-hiring/">About</a></li>
<li  id="menu-item-20220" class="menu-item menu-item-type-post_type menu-item-object-page current_page_parent"><a  href="https://www.dataquest.io/blog/">Blog</a></li>
<li  id="menu-item-20221" class="menu-item menu-item-type-custom menu-item-object-custom"><a  href="http://app.dataquest.io/signup">Start Learning</a></li>
<li  id="menu-item-20222" class="menu-item menu-item-type-custom menu-item-object-custom"><a  href="http://app.dataquest.io">Log In</a></li>
</ul></nav>														<div class="clear"></div>
						</div>
												<div class="clear"></div>
														</div>
			</div>
		</header>
			</div>
	
			



			<div class="bspr"></div>
<div class="wrp cnt">
			<div class="bSeCont">
				<section class="bSe left">

																	
<article>
	<div class="awr">
					<h1 class="entry-title">Tutorial: Learning Curves for Machine Learning in Python</h1>
							<noscript><img src="https://www.dataquest.io/wp-content/uploads/2019/01/topimage-781x520.jpeg" alt="python data science tutorial"
			     title="python data science tutorial"
			     class="fwI"/></noscript><img src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="https://www.dataquest.io/wp-content/uploads/2019/01/topimage-781x520.jpeg" alt="python data science tutorial"
			     title="python data science tutorial"
			     class="lazyload fwI"/>
		
		<div class="kg-card-markdown">
When building machine learning models, we want to keep error as low as possible. That&#8217;s a key skill for anyone aiming to learn Python for data science. Two major sources of error are bias and variance. If we managed to reduce these two, then we could build more accurate models.</p>
<p>But how do we diagnose bias and variance in the first place? And what actions should we take once we&#8217;ve detected something?</p>
<p>In this post, we&#8217;ll learn how to answer both these questions using learning curves. We&#8217;ll work with a real world data set and try to predict the electrical energy output of a power plant.</p>
<p>Some familiarity with scikit-learn and machine learning theory is assumed. If you don&#8217;t frown when I say <em>cross-validation</em> or <em>supervised learning</em>, then you&#8217;re good to go. If you&#8217;re new to machine learning and have never tried scikit, a good place to start is <a href="https://www.dataquest.io/blog/machine-learning-tutorial/">this blog post</a>.</p>
<p>We begin with a brief introduction to bias and variance.</p>
<h2 id="thebiasvariancetradeoff">
The bias-variance trade-off</h2>
<p>In supervised learning, we <em>assume</em> there&#8217;s a real relationship between feature(s) and target and estimate this unknown relationship with a model. Provided the assumption is true, there really is a model, which we&#8217;ll call \(f\), which describes perfectly the relationship between features and target.</p>
<p>In practice, \(f\) is almost always completely unknown, and we try to estimate it with a model \(\hat{f}\) (notice the slight difference in notation between \(f\) and \(\hat{f}\)). We use a <em>certain</em> training set and get a <em>certain</em> \(\hat{f}\). If we use a different training set, we are very likely to get a different \(\hat{f}\). As we keep changing training sets, we get different outputs for \(\hat{f}\). The amount by which \(\hat{f}\) varies as we change training sets is called <strong>variance</strong>.</p>
<p>To estimate the true \(f\), we use different methods, like linear regression or random forests. Linear regression, for instance, assumes linearity between features and target. For most real-life scenarios, however, the true relationship between features and target is complicated and far from linear. Simplifying assumptions give <strong>bias</strong> to a model. The more erroneous the assumptions with respect to the true relationship, the higher the bias, and vice-versa.</p>
<p>Generally, a model \(\hat{f}\) will have some error when tested on some test data. It can be shown <a href="https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff#Bias.E2.80.93variance_decomposition_of_squared_error">mathematically</a> that both bias and variance can only add to a model&#8217;s error. We want a low error, so we need to keep both bias and variance at their minimum. However, that&#8217;s not quite possible. There&#8217;s a trade-off between bias and variance.</p>
<p>A low-biased method fits training data very well. If we change training sets, we&#8217;ll get significantly different models \(\hat{f}\).</p>
<p><noscript><img src="/wp-content/uploads/2019/01/low_bias.png" alt="low_bias"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/low_bias.png" alt="low_bias"></p>
<p>You can see that a low-biased method captures most of the differences (even the minor ones) between the different training sets. \(\hat{f}\) <em>varies</em> a lot as we change training sets, and this indicates high variance.</p>
<p>The less biased a method, the greater its ability to fit data well. The greater this ability, the higher the variance. Hence, the lower the bias, the greater the variance.</p>
<p>The reverse also holds: the greater the bias, the lower the variance. A high-bias method builds simplistic models that generally don&#8217;t fit well training data. As we change training sets, the models \(\hat{f}\) we get from a high-bias algorithm are, generally, not very different from one another.</p>
<p><noscript><img src="/wp-content/uploads/2019/01/high_bias.png" alt="high_bias"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/high_bias.png" alt="high_bias"></p>
<p>If \(\hat{f}\) doesn&#8217;t change too much as we change training sets, the variance is low, which proves our point: the greater the bias, the lower the variance.</p>
<p>Mathematically, it&#8217;s clear why we want low bias and low variance. As mentioned above, bias and variance can only add to a model&#8217;s error. From a more intuitive perspective though, we want low bias to avoid building a model that&#8217;s too simple. In most cases, a simple model performs poorly on training data, and it&#8217;s extremely likely to repeat the poor performance on test data.</p>
<p>Similarly, we want low variance to avoid building an overly complex model. Such a model fits almost perfectly all the data points in the training set. Training data, however, generally contains noise and is only a sample from a much larger population. An overly complex model captures that noise. And when tested on <em>out-of-sample</em> data, the performance is usually poor. That&#8217;s because the model learns the <em>sample</em> training data too well. It knows a lot about something and little about anything else.</p>
<p>In practice, however, we need to accept a trade-off. We can&#8217;t have both low bias and low variance, so we want to aim for something in the middle.</p>
<p><noscript><img src="/wp-content/uploads/2019/01/biasvariance.png" alt="biasvariance"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/biasvariance.png" alt="biasvariance"></p>
<p>We&#8217;ll try to build some practical intuition for this trade-off as we generate and interpret learning curves below.</p>
<h2 id="learningcurvesthebasicidea">
Learning curves &#8211; the basic idea</h2>
<p>Let&#8217;s say we have some data and split it into a training set and <a href="https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set#19051">validation</a> set. We take one single instance (that&#8217;s right, one!) from the training set and use it to estimate a model. Then we measure the model&#8217;s error on the validation set and on that single training instance. The error on the training instance will be 0, since it&#8217;s quite easy to perfectly fit a single data point. The error on the validation set, however, will be very large.</p>
<p>That&#8217;s because the model is built around a single instance, and it almost certainly won&#8217;t be able to generalize accurately on data that hasn&#8217;t seen before. Now let&#8217;s say that instead of one training instance, we take ten and repeat the error measurements. Then we take fifty, one hundred, five hundred, until we use our entire training set. The error scores will vary more or less as we change the training set. We thus have two error scores to monitor: one for the validation set, and one for the training sets. If we plot the evolution of the two error scores as training sets change, we end up with two curves. These are called <em>learning curves</em>. In a nutshell, a learning curve shows how error changes as the training set size increases.</p>
<p>The diagram below should help you visualize the process described so far. On the training set column you can see that we constantly increase the size of the training sets. This causes a slight change in our models \(\hat{f}\). In the first row, where n = 1 (<em>n</em> is the number of training instances), the model fits perfectly that single training data point. However, the very same model fits really bad a validation set of 20 different data points. So the model&#8217;s error is 0 on the training set, but much higher on the validation set. As we increase the training set size, the model cannot fit perfectly anymore the training set. So the training error becomes larger. However, the model is trained on more data, so it manages to fit better the validation set. Thus, the validation error decreases. To remind you, the validation set stays the same across all three cases. <noscript><img src="/wp-content/uploads/2019/01/models.png" alt="models"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/models.png" alt="models"> If we plotted the error scores for each training size, we&#8217;d get two learning curves looking similarly to these: <noscript><img src="/wp-content/uploads/2019/01/learning_curves.png" alt="learning_curves"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/learning_curves.png" alt="learning_curves"> Learning curves give us an opportunity to diagnose bias and variance in supervised learning models. We&#8217;ll see how that&#8217;s possible in what follows.</p>
<h2 id="introducingthedata">
Introducing the data</h2>
<p>The learning curves plotted above are idealized for teaching purposes. In practice, however, they usually look significantly different. So let&#8217;s move the discussion in a practical setting by using some real-world data. We&#8217;ll try to build regression models that predict the hourly electrical energy output of a power plant. The data we use come from Turkish researchers Pnar Tfekci and Heysem Kaya, and can be downloaded from <a href="https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant">here</a>. As the data is stored in a <code>.xlsx</code> file, we use pandas&#8217; <code>read_excel()</code> <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html?highlight=read_excel#pandas.read_excel">function</a> to read it in:</p>
<pre class="language-python"><code class="language-python">import pandas as pd
electricity = pd.read_excel('Folds5x2_pp.xlsx')
print(electricity.info())
electricity.head(3)</code></pre>
<pre class="language-python"><code class="language-python">&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 9568 entries, 0 to 9567
Data columns (total 5 columns):
AT 9568 non-null float64
V 9568 non-null float64
AP 9568 non-null float64
RH 9568 non-null float64
PE 9568 non-null float64
dtypes: float64(5)
memory usage: 373.8 KB
None</code></pre>
<div>
<style scoped="">
.dataframe tbody tr th:only-of-type { vertical-align: middle; }</p>
<pre class="language-python"><code>.dataframe tbody tr th { vertical-align: top;}.dataframe thead th { text-align: right;}</code></pre>
</style>
<table border="1" class="dataframe">
<thead>
<tr style="text-align: right;">
<th></th>
<th>
AT</th>
<th>
V</th>
<th>
AP</th>
<th>
RH</th>
<th>
PE</th>
</tr>
</thead>
<tbody>
<tr>
<th>
0</th>
<td>
14.96</td>
<td>
41.76</td>
<td>
1024.07</td>
<td>
73.17</td>
<td>
463.26</td>
</tr>
<tr>
<th>
1</th>
<td>
25.18</td>
<td>
62.96</td>
<td>
1020.04</td>
<td>
59.08</td>
<td>
444.37</td>
</tr>
<tr>
<th>
2</th>
<td>
5.11</td>
<td>
39.40</td>
<td>
1012.16</td>
<td>
92.14</td>
<td>
488.56</td>
</tr>
</tbody>
</table>
</div>
<p>Let&#8217;s quickly decipher each column name:</p>
<table>
<thead>
<tr>
<th>
Abbreviation</th>
<th>
Full name</th>
</tr>
</thead>
<tbody>
<tr>
<td>
AT</td>
<td>
Ambiental Temperature</td>
</tr>
<tr>
<td>
V</td>
<td>
Exhaust Vacuum</td>
</tr>
<tr>
<td>
AP</td>
<td>
Ambiental Pressure</td>
</tr>
<tr>
<td>
RH</td>
<td>
Relative Humidity</td>
</tr>
<tr>
<td>
PE</td>
<td>
Electrical Energy Output</td>
</tr>
</tbody>
</table>
<p>The <code>PE</code> column is the target variable, and it describes the net hourly electrical energy output. All the other variables are potential features, and the values for each are actually hourly averages (not net values, like for <code>PE</code>). The electricity is generated by gas turbines, steam turbines, and heat recovery steam generators. According to the documentation of the data set, the vacuum level has an effect on steam turbines, while the other three variables affect the gas turbines. Consequently, we&#8217;ll use all of the feature columns in our regression models. At this step we&#8217;d normally put aside a test set, explore the training data thoroughly, remove any outliers, measure correlations, etc. For teaching purposes, however, we&#8217;ll assume that&#8217;s already done and jump straight to generate some learning curves. Before we start that, it&#8217;s worth noticing that there are no missing values. Also, the numbers are unscaled, but we&#8217;ll avoid using models that have problems with unscaled data.</p>
<h2 id="decidinguponthetrainingsetsizes">
Deciding upon the training set sizes</h2>
<p>Let&#8217;s first decide what training set sizes we want to use for generating the learning curves. The minimum value is 1. The maximum is given by the number of instances in the training set. Our training set has 9568 instances, so the maximum value is 9568. However, we haven&#8217;t yet put aside a validation set. We&#8217;ll do that using an 80:20 ratio, ending up with a training set of 7654 instances (80%), and a validation set of 1914 instances (20%). Given that our training set will have 7654 instances, the maximum value we can use to generate our learning curves is 7654. For our case, here, we use these six sizes:</p>
<pre class="language-python"><code>train_sizes = [1, 100, 500, 2000, 5000, 7654]</code></pre>
<p>An important thing to be aware of is that for each specified size a new model is trained. If you&#8217;re using cross-validation, which we&#8217;ll do in this post, <em>k</em> models will be trained for each training size (where <em>k</em> is given by the number of folds used for cross-validation). To save code running time, it&#8217;s good practice to limit yourself to 5-10 training sizes.</p>
<h2 id="thelearning_curvefunctionfromscikitlearn">
The learning_curve() function from scikit-learn</h2>
<p>We&#8217;ll use the <code>learning_curve()</code> <a href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html">function</a> from the scikit-learn library to generate a learning curve for a regression model. There&#8217;s no need on our part to put aside a validation set because <code>learning_curve()</code> will take care of that. In the code cell below, we:</p>
<ul>
<li>
Do the required imports from <code>sklearn</code>.</li>
<li>
Declare the features and the target.</li>
<li>
Use <code>learning_curve()</code> to generate the data needed to plot a learning curve. The function returns a tuple containing three elements: the training set sizes, and the error scores on both the validation sets and the training sets. Inside the function, we use the following parameters:</p>
<ul>
<li>
<code>estimator</code>  indicates the learning algorithm we use to estimate the true model;</li>
<li>
<code>X</code>  the data containing the features;</li>
<li>
<code>y</code>  the data containing the target;</li>
<li>
<code>train_sizes</code>  specifies the training set sizes to be used;</li>
<li>
<code>cv</code>  determines the cross-validation splitting strategy (we&#8217;ll discuss this immediately);</li>
<li>
<code>scoring</code>  indicates the error metric to use; the intention is to use the mean squared error (MSE) metric, but that&#8217;s not a possible parameter for <code>scoring</code>; we&#8217;ll use the nearest proxy, negative MSE, and we&#8217;ll just have to flip signs later on.</li>
</ul>
</li>
</ul>
<pre class="language-python"><code class="language-python">
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import learning_curve
features = ['AT', 'V', 'AP', 'RH']
target = 'PE'
train_sizes, train_scores, validation_scores = learning_curve(
estimator = LinearRegression(),
X = electricity[features],
y = electricity[target], train_sizes = train_sizes, cv = 5,
scoring = 'neg_mean_squared_error')</code></pre>
<p>We already know what&#8217;s in <code>train_sizes</code>. Let&#8217;s inspect the other two variables to see what <code>learning_curve()</code> returned:</p>
<pre class="language-python"><code class="language-python">
print('Training scores:\n\n', train_scores)
print('\n', '-' * 70) # separator to make the output easy to read
print('\nValidation scores:\n\n', validation_scores)</code></pre>
<pre class="language-python"><code class="language-python">
Training scores:
[[ -0. -0. -0. -0. -0. ] [-19.71230701 -18.31492642 -18.31492642 -18.31492642 -18.31492642] [-18.14420459 -19.63885072 -19.63885072 -19.63885072 -19.63885072] [-21.53603444 -20.18568787 -19.98317419 -19.98317419 -19.98317419] [-20.47708899 -19.93364211 -20.56091569 -20.4150839 -20.4150839 ] [-20.98565335 -20.63006094 -21.04384703 -20.63526811 -20.52955609]] --------------------------------------------------------------------Validation scores:
[[-619.30514723 -379.81090366 -374.4107861 370.03037109 -373.30597982]
[ -21.80224219 -23.01103419 20.81350389 -22.88459236 -23.44955492]
[ -19.96005238 -21.2771561 19.75136596 -21.4325615 -21.89067652]
[ -19.92863783 21.35440062 19.62974239 -21.38631648 -21.811031 ]
[ -19.88806264 -21.3183303 19.68228562 -21.35019525 -21.75949097]
[ -19.9046791 21.33448781 19.67831137 -21.31935146 -21.73778949]]</code></pre>
<p>Since we specified six training set sizes, you might have expected six values for each kind of score. Instead, we got six rows for each, and every row has five error scores. This happens because <code>learning_curve()</code> runs a <code>k</code>-fold cross-validation under the hood, where the value of <code>k</code> is given by what we specify for the <code>cv</code> parameter. In our case, <code>cv = 5</code>, so there will be five splits. For each split, an estimator is trained for every training set size specified. Each column in the two arrays above designates a split, and each row corresponds to a test size. Below is a table for the training error scores to help you understand the process better:</p>
<table>
<thead>
<tr>
<th>
Training set size (index)</th>
<th>
Split1</th>
<th>
Split2</th>
<th>
Split3</th>
<th>
Split4</th>
<th>
Split5</th>
</tr>
</thead>
<tbody>
<tr>
<td>
1</td>
<td>
0</td>
<td>
0</td>
<td>
0</td>
<td>
0</td>
<td>
0</td>
</tr>
<tr>
<td>
100</td>
<td>
-19.71230701</td>
<td>
-18.31492642</td>
<td>
-18.31492642</td>
<td>
-18.31492642</td>
<td>
-18.31492642</td>
</tr>
<tr>
<td>
500</td>
<td>
-18.14420459</td>
<td>
-19.63885072</td>
<td>
-19.63885072</td>
<td>
-19.63885072</td>
<td>
-19.63885072</td>
</tr>
<tr>
<td>
2000</td>
<td>
-21.53603444</td>
<td>
-20.18568787</td>
<td>
-19.98317419</td>
<td>
-19.98317419</td>
<td>
-19.98317419</td>
</tr>
<tr>
<td>
5000</td>
<td>
-20.47708899</td>
<td>
-19.93364211</td>
<td>
-20.56091569</td>
<td>
-20.4150839</td>
<td>
-20.4150839</td>
</tr>
<tr>
<td>
7654</td>
<td>
-20.98565335</td>
<td>
-20.63006094</td>
<td>
-21.04384703</td>
<td>
-20.63526811</td>
<td>
-20.52955609</td>
</tr>
</tbody>
</table>
<p>To plot the learning curves, we need only a single error score per training set size, not 5. For this reason, in the next code cell we take the mean value of each row and also flip the signs of the error scores (as discussed above).</p>
<pre class="language-python"><code class="language-python">
train_scores_mean = -train_scores.mean(axis = 1)
validation_scores_mean = -validation_scores.mean(axis = )
print('Mean training scores\n\n', pd.Series(train_scores_mean, index = train_sizes))
print('\n', '-' * 20) # separator
print('\nMean validation scores\n\n',pd.Series(validation_scores_mean, index = train_sizes))</code></pre>
<pre class="language-python"><code class="language-python">
Mean training scores
1 -0.000000
100 18.594403
500 19.339921
2000 20.334249
5000 20.360363
7654 20.764877
dtype: float64
--------------------
Mean validation scores
1 423.372638
100 22.392186
500 20.862362
2000 20.822026
5000 20.799673
7654 20.794924
dtype: float64
</code></pre>
<p>Now we have all the data we need to plot the learning curves. Before doing the plotting, however, we need to stop and make an important observation. You might have noticed that some error scores on the <em>training</em> sets are the same. For the row corresponding to training set size of 1, this is expected, but what about other rows? With the exception of the last row, we have a lot of identical values. For instance, take the second row where we have identical values from the second split onward. Why is that so? This is caused by not randomizing the <em>training</em> data for each split. Let&#8217;s walk through a single example with the aid of the diagram below. When the training size is 500 the first 500 instances in the training set are selected.</p>
<p>For the first split, these 500 instances will be taken from the second chunk. From the second split onward, these 500 instances will be taken from the first chunk. Because we don&#8217;t randomize the training set, the 500 instances used for training are the same for the second split onward. This explains the identical values from the second split onward for the 500 training instances case. An identical reasoning applies to the 100 instances case, and a similar reasoning applies to the other cases. <noscript><img src="/wp-content/uploads/2019/01/splits.png" alt="splits"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/splits.png" alt="splits"> To stop this behavior, we need to set the <code>shuffle</code> parameter to <code>True</code> in the <code>learning_curve()</code> function. This will randomize the indices for the <em>training</em> data for each split. We haven&#8217;t randomized above for two reasons:</p>
<ul>
<li>
The data comes pre-shuffled five times (as mentioned in the <a href="https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant">documentation</a>) so there&#8217;s no need to randomize anymore.</li>
<li>
I wanted to make you aware about this quirk in case you stumble upon it in practice.</li>
</ul>
<p>Finally, let&#8217;s do the plotting.</p>
<h2 id="learningcurveshighbiasandlowvariance">
Learning curves &#8211; high bias and low variance</h2>
<p>We plot the learning curves using a regular matplotlib workflow:</p>
<pre class="language-python"><code class="language-python">
import matplotlib.pyplot as plt

plt.style.use('seaborn')
plt.plot(train_sizes, train_scores_mean, label = 'Training error')
plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')
plt.ylabel('MSE', fontsize = 14)
plt.xlabel('Training set size', fontsize = 14)
plt.title('Learning curves for a linear regression model', fontsize = 18, y = 1.03)
plt.legend()
plt.ylim(0,40)</code></pre>
<pre class="language-python"><code>(0, 40)</code></pre>
<p><noscript><img src="/wp-content/uploads/2019/01/Learning_curves_12_1.png" alt="Learning_curves_12_1"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/Learning_curves_12_1.png" alt="Learning_curves_12_1"></p>
<p>There&#8217;s a lot of information we can extract from this plot. Let&#8217;s proceed granularly. When the training set size is 1, we can see that the MSE for the training set is 0. This is normal behavior, since the model has no problem fitting perfectly a single data point. So when tested upon the same data point, the prediction is perfect. But when tested on the validation set (which has 1914 instances), the MSE rockets up to roughly 423.4. This relatively high value is the reason we restrict the y-axis range between 0 and 40. This enables us to read most MSE values with precision. Such a high value is expected, since it&#8217;s extremely unlikely that a model trained on a single data point can generalize accurately to 1914 new instances it hasn&#8217;t seen in training. When the training set size increases to 100, the training MSE increases sharply, while the validation MSE decreases likewise.</p>
<p>The linear regression model doesn&#8217;t predict all 100 training points perfectly, so the training MSE is greater than 0. However, the model performs much better now on the validation set because it&#8217;s estimated with more data. From 500 training data points onward, the validation MSE stays roughly the same. This tells us something extremely important: adding more training data points won&#8217;t lead to significantly better models. So instead of wasting time (and possibly money) with collecting more data, we need to try something else, like switching to an algorithm that can build more complex models. <noscript><img src="/wp-content/uploads/2019/01/add_data.png" alt="add_data"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/add_data.png" alt="add_data"></p>
<p>To avoid a misconception here, it&#8217;s important to notice that what really won&#8217;t help is adding more <em>instances</em> (rows) to the training data. Adding more features, however, is a different thing and is very likely to help because it will increase the complexity of our current model. Let&#8217;s now move to diagnosing bias and variance. The main indicator of a bias problem is a high validation error. In our case, the validation MSE stagnates at a value of approximately 20. But how good is that? We&#8217;d benefit from some domain knowledge (perhaps physics or engineering in this case) to answer this, but let&#8217;s give it a try.</p>
<p>Technically, that value of 20 has MW\(^2\) (megawatts squared) as units (the units get squared as well <a href="https://en.wikipedia.org/wiki/Mean_squared_error#Predictor">when we compute the MSE</a>). But the values in our target column are in MW (according to the <a href="https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant">documentation</a>). Taking the square root of 20 MW\(^2\) results in approximately 4.5 MW. Each target value represents net <em>hourly</em> electrical energy output. So for each hour our model is off by 4.5 MW on average. According to <a href="https://www.quora.com/How-can-I-get-an-intuitive-understanding-of-what-a-Kw-Mw-Gw-of-electricity-equates-to-in-real-life-terms">this Quora answer</a>, 4.5 MW is equivalent to the heat power produced by 4500 handheld hair dryers. And this would add up if we tried to predict the total energy output for one day or a longer period. We can conclude that the an MSE of 20 MW\(^2\) is quite large. So our model has a bias problem.</p>
<p>But is it a <em>low</em> bias problem or a <em>high</em> bias problem? To find the answer, we need to look at the training error. If the training error is very low, it means that the training data is fitted very well by the estimated model. If the model fits the training data very well, it means it has <em>low</em> bias with respect to that set of data. If the training error is high, it means that the training data is not fitted well enough by the estimated model. If the model fails to fit the training data well, it means it has <em>high</em> bias with respect to that set of data. <noscript><img src="/wp-content/uploads/2019/01/low_high_bias.png" alt="low_high_bias"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/low_high_bias.png" alt="low_high_bias"></p>
<p>In our particular case, the training MSE plateaus at a value of roughly 20 MW\(^2\). As we&#8217;ve already established, this is a high error score. Because the validation MSE is high, and the training MSE is high as well, our model has a high bias problem. Now let&#8217;s move with diagnosing eventual variance problems. Estimating variance can be done in at least two ways:</p>
<ul>
<li>
By examining the gap between the validation learning curve and training learning curve.</li>
<li>
By examining the training error: its value and its evolution as the training set sizes increase.</li>
</ul>
<p><noscript><img src="/wp-content/uploads/2019/01/lc_regression.png" alt="lc_regression"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/lc_regression.png" alt="lc_regression"></p>
<p>A narrow gap indicates low variance. Generally, the more narrow the gap, the lower the variance. The opposite is also true: the wider the gap, the greater the variance. Let&#8217;s now explain why this is the case. As we&#8217;ve discussed earlier, if the variance is high, then the model fits training data too well. When training data is fitted too well, the model will have trouble generalizing on data that hasn&#8217;t seen in training. When such a model is tested on its training set, and then on a validation set, the training error will be low and the validation error will generally be high. As we change training set sizes, this pattern continues, and the differences between training and validation errors will determine that gap between the two learning curves.</p>
<p>The relationship between the training and validation error, and the gap can be summarized this way: \( gap = validation\ error &#8211; training\ error \) So the bigger the difference between the two errors, the bigger the gap. The bigger the gap, the bigger the variance. In our case, the gap is very narrow, so we can safely conclude that the variance is low. High <em>training</em> MSE scores are also a quick way to detect low variance. If the variance of a learning algorithm is low, then the algorithm will come up with simplistic and similar models as we change the training sets. Because the models are overly simplified, they cannot even fit the training data well (they <em>underfit</em> the data). So we should expect high training MSEs. Hence, high training MSEs can be used as indicators of low variance. <noscript><img src="/wp-content/uploads/2019/01/low_high_var.png" alt="low_high_var"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/low_high_var.png" alt="low_high_var"></p>
<p>In our case, the training MSE plateaus at around 20, and we&#8217;ve already concluded that&#8217;s a high value. So besides the narrow gap, we now have another confirmation that we have a low variance problem. So far, we can conclude that:</p>
<ul>
<li>
Our learning algorithm suffers from high bias and low variance, underfitting the training data.</li>
<li>
Adding more instances (rows) to the training data is hugely unlikely to lead to better models under the current learning algorithm.</li>
</ul>
<p>One solution at this point is to change to a more complex learning algorithm. This should decrease the bias and increase the variance. A mistake would be to try to increase the number of training instances. Generally, these other two fixes also work when dealing with a high bias and low variance problem:</p>
<ul>
<li>
Training the current learning algorithm on more features (to avoid <em>collecting</em> new data, you can generate easily <a href="http://scikit-learn.org/stable/modules/preprocessing.html">polynomial features</a>). This should lower the bias by increasing the model&#8217;s complexity.</li>
<li>
Decreasing the <a href="https://www.quora.com/What-is-regularization-in-machine-learning">regularization</a> of the current learning algorithm, if that&#8217;s the case. In a nutshell, regularization prevents the algorithm from fitting the training data too well. If we decrease regularization, the model will fit training data better, and, as a consequence, the variance will increase and the bias will decrease.</li>
</ul>
<h2 id="learningcurveslowbiasandhighvariance">
Learning curves &#8211; low bias and high variance</h2>
<p>Let&#8217;s see how an unregularized Random Forest regressor fares here. We&#8217;ll generate the learning curves using the same workflow as above. This time we&#8217;ll bundle everything into a function so we can use it for later. For comparison, we&#8217;ll also display the learning curves for the linear regression model above.</p>
<pre class="language-python"><code class="language-python">
### Bundling our previous work into a function ###
def learning_curves(estimator, data, features, target, train_sizes, cv):
   train_sizes, train_scores, validation_scores = learning_curve(
    estimator, data[features], data[target], train_sizes = 
    train_sizes,
    cv = cv, scoring = 'neg_mean_squared_error')
    train_scores_mean = -train_scores.mean(axis = 1)
    validation_scores_mean = -validation_scores.mean(axis = 1)
    
    plt.plot(train_sizes, train_scores_mean, label = 'Training error')
    plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')
    
    plt.ylabel('MSE', fontsize = 14)
    plt.xlabel('Training set size', fontsize = 14)
    title = 'Learning curves for a ' + str(estimator).split('(')[0] + ' model'
    plt.title(title, fontsize = 18, y = 1.03)
    plt.legend()
    plt.ylim(0,40)

### Plotting the two learning curves ###

from sklearn.ensemble import RandomForestRegressor

plt.figure(figsize = (16,5))

for model, i in [(RandomForestRegressor(), 1), (LinearRegression(),2)]:
    plt.subplot(1,2,i)
    learning_curves(model, electricity, features, target, train_sizes, 5)
</code></pre>
<p><noscript><img src="/wp-content/uploads/2019/01/Learning_curves_15_0.png" alt="Learning_curves_15_0"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/Learning_curves_15_0.png" alt="Learning_curves_15_0"></p>
<p>Now let&#8217;s try to apply what we&#8217;ve just learned. It&#8217;d be a good idea to pause reading at this point and try to interpret the new learning curves yourself. Looking at the validation curve, we can see that we&#8217;ve managed to decrease bias. There still is some significant bias, but not that much as before. Looking at the training curve, we can deduce that this time there&#8217;s a <em>low</em> bias problem.</p>
<p>The new gap between the two learning curves suggests a substantial increase in variance. The low training MSEs corroborate this diagnosis of high variance. The large gap and the low training error also indicates an overfitting problem. Overfitting happens when the model performs well on the training set, but far poorer on the test (or validation) set. One more important observation we can make here is that <em>adding new training instances</em> is very likely to lead to better models. The validation curve doesn&#8217;t plateau at the maximum training set size used. It still has potential to decrease and converge toward the training curve, similar to the convergence we see in the linear regression case. So far, we can conclude that:</p>
<ul>
<li>
Our learning algorithm (random forests) suffers from high variance and quite a low bias, overfitting the training data.</li>
<li>
Adding more training instances is very likely to lead to better models under the current learning algorithm.</li>
</ul>
<p>At this point, here are a couple of things we could do to improve our model:</p>
<ul>
<li>
Adding more training instances.</li>
<li>
Increase the regularization for our current learning algorithm. This should decrease the variance and increase the bias.</li>
<li>
Reducing the numbers of features in the training data we currently use. The algorithm will still fit the training data very well, but due to the decreased number of features, it will build less complex models. This should increase the bias and decrease the variance.</li>
</ul>
<p>In our case, we don&#8217;t have any other readily available data. We could go into the power plant and take some measurements, but we&#8217;ll save this for another post (just kidding). Let&#8217;s rather try to regularize our random forests algorithm. One way to do that is to adjust the maximum number of leaf nodes in each decision tree. This can be done by using the <code>max_leaf_nodes</code> parameter of <code>RandomForestRegressor()</code>. It&#8217;s not necessarily for you to understand this regularization technique. For our purpose here, what you need to focus on is the effect of this regularization on the learning curves.</p>
<pre class="language-python"><code>learning_curves(RandomForestRegressor(max_leaf_nodes = 350), electricity, features, target, train_sizes, 5)</code></pre>
<p><noscript><img src="/wp-content/uploads/2019/01/Learning_curves_17_0.png" alt="Learning_curves_17_0"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/Learning_curves_17_0.png" alt="Learning_curves_17_0"><br />
Not bad! The gap is now more narrow, so there&#8217;s less variance. The bias seems to have increased just a bit, which is what we wanted. But our work is far from over! The validation MSE still shows a lot of potential to decrease. Some steps you can take toward this goal include:</p>
<ul>
<li>
Adding more training instances.</li>
<li>
Adding more features.</li>
<li>
Feature selection.</li>
<li>
Hyperparameter optimization.</li>
</ul>
<h2 id="theideallearningcurvesandtheirreducibleerror">
The ideal learning curves and the irreducible error</h2>
<p>Learning curves constitute a great tool to do a quick check on our models at every point in our machine learning workflow. But how do we know when to stop? How do we recognize the perfect learning curves? For our regression case before, you might think that the perfect scenario is when both curves converge toward an MSE of 0. That&#8217;s a perfect scenario, indeed, but, unfortunately, it&#8217;s not possible. Neither in practice, neither in theory. And this is because of something called <em>irreducible error</em>. When we build a model to map the relationship between the features \(X\) and the target \(Y\), we assume that there is such a relationship in the first place.</p>
<p>Provided the assumption is true, there is a true model \(f\) that describes perfectly the relationship between \(X\) and \(Y\), like so:</p>
<p>$$<br />
Y = f(X) + irreducible\ error \tag{1}<br />
$$</p>
<p>But why is there an error?! Haven&#8217;t we just said that \(f\) describes the relationship between X and Y perfectly?! There&#8217;s an error there because \(Y\) is not only a function of our limited number of features \(X\). There could be many other features that influence the value of \(Y\). Features we don&#8217;t have. It might also be the case that \(X\) contains measurement errors. So, besides \(X\), \(Y\) is also a function of \(irreducible\ error\). Now let&#8217;s explain why this error is <em>irreducible</em>. When we estimate \(f(X)\) with a model \(\hat{f}(X)\), we introduce another kind of error, called <em>reducible</em> error:</p>
<p>$$<br />
f(X) = \hat{f}(X) + reducible\ error \tag{2}<br />
$$</p>
<p>Replacing \(f(X)\) in \((1)\) we get:</p>
<p>$$<br />
Y = \hat{f}(X) + reducible\ error + irreducible\ error \tag{3}<br />
$$</p>
<p>Error that is reducible can be reduced by building better models. Looking at equation \((2)\) we can see that if the \(reducible\ error\) is 0, our estimated model \(\hat{f}(X)\) is equal to the true model \(f(X)\).</p>
<p>However, from \((3)\) we can see that \(irreducible\ error\) remains in the equation even if \(reducible\ error\) is 0. From here we deduce that no matter how good our model estimate is, generally there still is some error we cannot reduce. And that&#8217;s why this error is considered <em>irreducible</em>. This tells us that that in practice the best possible learning curves we can see are those which converge to the value of some irreducible error, not toward some ideal error value (for MSE, the ideal error score is 0; we&#8217;ll see immediately that other error metrics have different ideal error values). <noscript><img src="/wp-content/uploads/2019/01/irr_error.png" alt="irr_error"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/irr_error.png" alt="irr_error"></p>
<p>In practice, the exact value of the irreducible error is almost always unknown. We also assume that the irreducible error is independent of \(X\). This means that we cannot use \(X\) to find the true irreducible error. Expressing the same thing in the more precise language of mathematics, there&#8217;s no function \(g\) to map \(X\) to the true value of the irreducible error:</p>
<p>$$<br />
irreducible\ error \neq g(X)<br />
$$</p>
<p>So there&#8217;s no way to know the true value of the irreducible error based on the data we have. In practice, a good workaround is to try to lower the error score as much as possible, while keeping in mind that the limit is given by some irreducible error.</p>
<h2 id="whataboutclassification">
What about classification?</h2>
<p>So far, we&#8217;ve learned about learning curves in a regression setting. For classification tasks, the workflow is almost identical. The main difference is that we&#8217;ll have to choose another error metric &#8211; one that is suitable for evaluating the performance of a classifier. Let&#8217;s see an example: <a href="http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html"><noscript><img src="/wp-content/uploads/2019/01/classification.png" alt="classification"></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20%20%22%3E%3C/svg%3E' data-src="/wp-content/uploads/2019/01/classification.png" alt="classification"></a></p>
<p>Unlike what we&#8217;ve seen so far, notice that the learning curve for the training error is above the one for the validation error. This is because the score used, <em>accuracy</em>, describes how good the model is. The higher the accuracy, the better. The MSE, on the other side, describes how bad a model is. The lower the MSE, the better. This has implications for the irreducible error as well. For error metrics that describe how bad a model is, the irreducible error gives a lower bound: you cannot get lower than that. For error metrics that describe how good a model is, the irreducible error gives an upper bound: you cannot get higher than that. As a side note here, in more technical writings the term <a href="https://en.wikipedia.org/wiki/Bayes_error_rate"><em>Bayes error rate</em></a> is what&#8217;s usually used to refer to the best possible error score of a classifier. The concept is analogous to the irreducible error.</p>
<h2 id="nextsteps">
Next steps</h2>
<p>Learning curves constitute a great tool to diagnose bias and variance in any supervised learning algorithm. We&#8217;ve learned how to generate them using scikit-learn and matplotlib, and how to use them to diagnose bias and variance in our models. To reinforce what you&#8217;ve learned, these are some next steps to consider:</p>
<ul>
<li>
Generate learning curves for a regression task using a different data set.</li>
<li>
Generate learning curves for a classification task.</li>
<li>
Generate learning curves for a supervised learning task by coding everything from scratch (don&#8217;t use <code>learning_curve()</code> from scikit-learn). Using cross-validation is optional.</li>
<li>
Compare learning curves obtained without cross-validating with curves obtained using cross-validation. The two kinds of curves should be for the same learning algorithm.</li>
</ul>
</div>
<span id="tho-end-content" style="display: block; visibility: hidden;"></span><div class="saboxplugin-wrap" itemtype="http://schema.org/Person" itemscope itemprop="author"><div class="saboxplugin-gravatar"><noscript><img src="https://www.dataquest.io/wp-content/uploads/2019/01/alex_olteanu_profile-1-150x150.jpg" width="100" height="100" alt="Alex Olteanu" class="avatar avatar-100 wp-user-avatar wp-user-avatar-100 alignnone photo" /></noscript><img src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22%3E%3C/svg%3E' data-src="https://www.dataquest.io/wp-content/uploads/2019/01/alex_olteanu_profile-1-150x150.jpg" width="100" height="100" alt="Alex Olteanu" class="lazyload avatar avatar-100 wp-user-avatar wp-user-avatar-100 alignnone photo" /></div><div class="saboxplugin-authorname"><a href="https://www.dataquest.io/blog/author/alex-olteanu/" class="vcard author" rel="author" itemprop="url"><span class="fn" itemprop="name">Alex Olteanu</span></a></div><div class="saboxplugin-desc"><div itemprop="description"><p>Alex is a content author at Dataquest and writes courses on statistics and Python.</p>
</div></div><div class="clearfix"></div></div>
		<div class="clear"></div>
				<div class="clear"></div>
							<footer>
				<ul class="meta left">
					<li>
																											in																<span>
                                        <a href="https://www.dataquest.io/blog/topics/data-science-tutorials/">
	                                        Data Science Tutorials                                        </a>
									                                    </span>
																				
																				by <a
								href="https://www.dataquest.io/blog/author/alex-olteanu/">Alex Olteanu</a>
											</li>
																		<li class="sep">|</li>
												<li>
															January 3, 2018													</li>
														</ul>
								<div class="clear"></div>
			</footer>
					</div>

</article>
<div class="rltpi clearfix">
	<div class="awr">
		<h5>Related Posts</h5>
					<a href="https://www.dataquest.io/blog/data-pipelines-tutorial/" class="rlt left">
				<div class="rlti"  style="background-image: url('https://www.dataquest.io/wp-content/uploads/data-pipeline.png')"></div>
				<p>Tutorial: Building An Analytics Data Pipeline In Python</p>
			</a>
					<a href="https://www.dataquest.io/blog/python-datetime-tutorial/" class="rlt left">
				<div class="rlti"  style="background-image: url('https://www.dataquest.io/wp-content/uploads/2019/10/python-datetime-tutorial-510x162.jpg')"></div>
				<p>Python Datetime Tutorial: Manipulate Times, Dates, and Time Spans</p>
			</a>
					<a href="https://www.dataquest.io/blog/python-range-tutorial/" class="rlt left">
				<div class="rlti"  style="background-image: url('https://www.dataquest.io/wp-content/uploads/2019/10/python-range-tutorial-numbers-510x162.jpg')"></div>
				<p>Python Range Tutorial: Learn to Use This Helpful Built-In Function</p>
			</a>
					<a href="https://www.dataquest.io/blog/python-if-else/" class="rlt left">
				<div class="rlti"  style="background-image: url('https://www.dataquest.io/wp-content/uploads/2019/10/tacos-2338015-510x162.jpg')"></div>
				<p>Python if else Tutorial: Control the Flow of Your Code</p>
			</a>
					</div>
</div><div class="spr"></div>																					
	<script type="text/javascript">
		_thriveCurrentPost = 1998;
	</script>
	<article id="comments">
		<div class="awr">
			
			
			<div id="thrive_container_list_comments">
							</div>

			
					</div>
	</article>
	<div id="comment-bottom"></div>

																			</section>
			</div>
			
	<div class="sAsCont">
		<aside class="sAs right">
							<section id="custom_html-2"><div class="widget_text scn"><div class="textwidget custom-html-widget"><span style="display:none" class="tl-placeholder-f-type-shortcode_11317"></span></div></div></section><section id="search-3"><div class="scn"><form action="https://www.dataquest.io/" method="get" class="srh">
	<div>
		<input type="text" placeholder="Search" class="search-field" name="s"/>
		<button type="submit" class="search-button sBn"></button>
		<div class="clear"></div>
	</div>
</form>
</div></section><section id="nav_menu-3"><div class="scn"><p class="ttl">Browse the blog:</p><div class="menu-left-container"><ul id="menu-left" class="menu"><li id="menu-item-14042" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-14042"><a href="https://www.dataquest.io/blog/data-science-career-guide/">Job Application Guide</a></li>
<li id="menu-item-5973" class="menu-item menu-item-type-taxonomy menu-item-object-category current-post-ancestor current-menu-parent current-post-parent menu-item-5973"><a href="https://www.dataquest.io/blog/topics/data-science-tutorials/">Tutorials</a></li>
<li id="menu-item-5978" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-5978"><a href="https://www.dataquest.io/blog/topics/student-stories/">Student Stories</a></li>
<li id="menu-item-5974" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-5974"><a href="https://www.dataquest.io/blog/topics/learning-and-motivation/">Learning and Motivation</a></li>
<li id="menu-item-5979" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-5979"><a href="https://www.dataquest.io/blog/topics/building-a-data-science-portfolio/">How to Build a Portfolio</a></li>
<li id="menu-item-5977" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item-5977"><a href="https://www.dataquest.io/blog/topics/data-science-projects/">Data Science Projects</a></li>
</ul></div></div></section><section id="nav_menu-10"><div class="scn"><p class="ttl">More resources:</p><div class="menu-more-resources-container"><ul id="menu-more-resources" class="menu"><li id="menu-item-19385" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-19385"><a href="https://www.dataquest.io/data-science-courses/">Data Science Courses</a></li>
<li id="menu-item-19386" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-19386"><a href="https://www.dataquest.io/python-tutorials-for-data-science/">Python Tutorials</a></li>
<li id="menu-item-19388" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-19388"><a href="https://www.dataquest.io/blog/data-analyst-data-scientist-data-engineer/">Data Analyst vs. Scientist vs. Engineer</a></li>
</ul></div></div></section>			
		</aside>
	</div>

		<div class="clear"></div>
</div>
<div class="clear"></div>
</div>



<footer>
			<div class="ftw" id="dq_footer">
			<div class="wrp cnt">
									<div class="colm twc ">
						<section id="text-5">			<div class="textwidget"><div style="margin: 20px 0px 20px 0px;">
<p><a href="/"><noscript><img src="https://www.dataquest.io/wp-content/uploads/2019/01/dq-1.png" width="170px" height="28px" /></noscript><img class="lazyload" src='data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20170%2028%22%3E%3C/svg%3E' data-src="https://www.dataquest.io/wp-content/uploads/2019/01/dq-1.png" width="170px" height="28px" /></a></p>
</div>
<div style="margin: 20px 0px 20px 0px;">All rights reserved  2019  Dataquest Labs, Inc.</div>
<div style="margin: 20px 50px 20px 0px;">We are committed to protecting your personal information and your right to privacy. Privacy Policy last updated June 13th, 2019 &#8211; <a style="color: #ffffff; font-size: 12px;" href="/privacy">review here</a>.</div>
</div>
		</section>					</div>
									<div class="colm twc lst">
						<section id="text-9">			<div class="textwidget"><div class="footer-links" style="font-size: 12px; margin: 20px 0px 0px 0px;">
<div style="float: left; margin-right: 50px;"><a href="https://www.dataquest.io/help" target="_blank" rel="noopener noreferrer">Help</a><br />
<a href="https://www.dataquest.io/blog" target="_blank" rel="noopener noreferrer">Blog</a><br />
<a href="https://www.dataquest.io/directory">Directory</a><br />
<a href="https://community.dataquest.io" target="_blank" rel="noopener noreferrer">Community</a></div>
<div style="float: left; margin-right: 50px;"><a href="https://www.dataquest.io/subscribe">Pricing</a><br />
<a href="https://www.dataquest.io/were-hiring">We&#8217;re Hiring</a><br />
<a href="https://www.dataquest.io/terms">Legals</a><br />
<a href="https://www.dataquest.io/privacy">Privacy</a></div>
<div style="float: left; margin-bottom: 100px;"><a href="https://www.facebook.com/dataquestio" target="_blank" rel="noopener noreferrer">Facebook</a><br />
<a href="https://twitter.com/dataquestio" target="_blank" rel="noopener noreferrer">Twitter</a><br />
<a href="https://www.linkedin.com/company/dataquest-io" target="_blank" rel="noopener noreferrer">LinkedIn</a></div>
</div>
</div>
		</section>					</div>
								<div class="clear"></div>
			</div>
		</div>
			<div class="copy">
		<div class="wrp cnt">
			<p>
											</p>
					</div>
	</div>
	</footer>


	<script>
  !function(){var analytics=window.analytics=window.analytics||[];if(!analytics.initialize)if(analytics.invoked)window.console&&console.error&&console.error("Segment snippet included twice.");else{analytics.invoked=!0;analytics.methods=["trackSubmit","trackClick","trackLink","trackForm","pageview","identify","reset","group","track","ready","alias","debug","page","once","off","on"];analytics.factory=function(t){return function(){var e=Array.prototype.slice.call(arguments);e.unshift(t);analytics.push(e);return analytics}};for(var t=0;t<analytics.methods.length;t++){var e=analytics.methods[t];analytics[e]=analytics.factory(e)}analytics.load=function(t,e){var n=document.createElement("script");n.type="text/javascript";n.async=!0;n.src="https://cdn.segment.com/analytics.js/v1/"+t+"/analytics.min.js";var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(n,a);analytics._loadOptions=e};analytics.SNIPPET_VERSION="4.1.0";
  analytics.load("BJhKYEXejzjqXq7xQDFI6N0M5W7HBAH5");
  analytics.page();
  }}();
</script><script type='text/javascript'>
/* <![CDATA[ */
var TVE_Ult_Data = {"ajaxurl":"https:\/\/www.dataquest.io\/wp-admin\/admin-ajax.php","ajax_load_action":"tve_ult_ajax_load","conversion_events_action":"tve_ult_conversion_event","shortcode_campaign_ids":[],"matched_display_settings":[],"campaign_ids":[],"post_id":1998,"is_singular":true,"tu_em":""};
/* ]]> */
</script>
		<script type="text/javascript" src="https://www.dataquest.io/wp-content/plugins/thrive-ultimatum/js/dist/no-campaign.min.js?v=2.2.4.2"></script><style>.lazyload,.lazyloading{opacity:0;}.lazyloaded{opacity:1;transition:opacity 300ms;}</style><noscript><style>.lazyload{display:none;}</style></noscript><script data-noptimize="1">window.lazySizesConfig=window.lazySizesConfig||{};window.lazySizesConfig.loadMode=1;</script><script async data-noptimize="1" src='https://www.dataquest.io/wp-content/plugins/autoptimize/classes/external/js/lazysizes.min.js'></script>        <script type='text/javascript'>
        newContainer = document.createElement('span');
        newContainer.style.setProperty('display','none','');
        newNode = document.createElement('script');
        newNode.type = 'math/tex';
        newNode.innerHTML = '\\newcommand{\\eps}{\\varepsilon}\n\\newcommand{\\RR}{\\mathbb{R}}\n\\newcommand{\\rd}{\\operatorname{d}}\n\\newcommand{\\set}[1]{\\left\\{#1\\right\\}}';
        newContainer.appendChild(newNode);
        document.body.insertBefore(newContainer,document.body.firstChild);
        </script>
        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ["\\(","\\)"]],
    displayMath: [['$$', '$$'], ["\\[", "\\]"]],
    processEscapes: true
  },
  TeX: {
    equationNumbers: {autoNumber: "AMS",
    useLabelIds: true}
  },
}); 
        </script>
  <script data-cfasync="false" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG.js"></script>
<style type="text/css">.saboxplugin-wrap{-webkit-box-sizing:border-box;-moz-box-sizing:border-box;-ms-box-sizing:border-box;box-sizing:border-box;border:1px solid #eee;width:100%;clear:both;display:block;overflow:hidden;word-wrap:break-word;position:relative}.saboxplugin-wrap .saboxplugin-gravatar{float:left;padding:20px}.saboxplugin-wrap .saboxplugin-gravatar img{max-width:100px;height:auto;border-radius:0;}.saboxplugin-wrap .saboxplugin-authorname{font-size:18px;line-height:1;margin:20px 0 0 20px;display:block}.saboxplugin-wrap .saboxplugin-authorname a{text-decoration:none}.saboxplugin-wrap .saboxplugin-authorname a:focus{outline:0}.saboxplugin-wrap .saboxplugin-desc{display:block;margin:5px 20px}.saboxplugin-wrap .saboxplugin-desc a{text-decoration:underline}.saboxplugin-wrap .saboxplugin-desc p{margin:5px 0 12px}.saboxplugin-wrap .saboxplugin-web{margin:0 20px 15px;text-align:left}.saboxplugin-wrap .sab-web-position{text-align:right}.saboxplugin-wrap .saboxplugin-web a{color:#ccc;text-decoration:none}.saboxplugin-wrap .saboxplugin-socials{position:relative;display:block;background:#fcfcfc;padding:5px;border-top:1px solid #eee}.saboxplugin-wrap .saboxplugin-socials a svg{width:20px;height:20px}.saboxplugin-wrap .saboxplugin-socials a svg .st2{fill:#fff; transform-origin:center center;}.saboxplugin-wrap .saboxplugin-socials a svg .st1{fill:rgba(0,0,0,.3)}.saboxplugin-wrap .saboxplugin-socials a:hover{opacity:.8;-webkit-transition:opacity .4s;-moz-transition:opacity .4s;-o-transition:opacity .4s;transition:opacity .4s;box-shadow:none!important;-webkit-box-shadow:none!important}.saboxplugin-wrap .saboxplugin-socials .saboxplugin-icon-color{box-shadow:none;padding:0;border:0;-webkit-transition:opacity .4s;-moz-transition:opacity .4s;-o-transition:opacity .4s;transition:opacity .4s;display:inline-block;color:#fff;font-size:0;text-decoration:inherit;margin:5px;-webkit-border-radius:0;-moz-border-radius:0;-ms-border-radius:0;-o-border-radius:0;border-radius:0;overflow:hidden}.saboxplugin-wrap .saboxplugin-socials .saboxplugin-icon-grey{text-decoration:inherit;box-shadow:none;position:relative;display:-moz-inline-stack;display:inline-block;vertical-align:middle;zoom:1;margin:10px 5px;color:#444}.clearfix:after,.clearfix:before{content:' ';display:table;line-height:0;clear:both}.ie7 .clearfix{zoom:1}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-twitch{border-color:#38245c}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-addthis{border-color:#e91c00}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-behance{border-color:#003eb0}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-delicious{border-color:#06c}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-deviantart{border-color:#036824}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-digg{border-color:#00327c}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-dribbble{border-color:#ba1655}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-facebook{border-color:#1e2e4f}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-flickr{border-color:#003576}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-github{border-color:#264874}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-google{border-color:#0b51c5}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-googleplus{border-color:#96271a}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-html5{border-color:#902e13}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-instagram{border-color:#1630aa}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-linkedin{border-color:#00344f}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-pinterest{border-color:#5b040e}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-reddit{border-color:#992900}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-rss{border-color:#a43b0a}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-sharethis{border-color:#5d8420}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-skype{border-color:#00658a}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-soundcloud{border-color:#995200}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-spotify{border-color:#0f612c}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-stackoverflow{border-color:#a95009}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-steam{border-color:#006388}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-user_email{border-color:#b84e05}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-stumbleUpon{border-color:#9b280e}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-tumblr{border-color:#10151b}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-twitter{border-color:#0967a0}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-vimeo{border-color:#0d7091}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-windows{border-color:#003f71}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-whatsapp{border-color:#003f71}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-wordpress{border-color:#0f3647}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-yahoo{border-color:#14002d}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-youtube{border-color:#900}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-xing{border-color:#000202}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-mixcloud{border-color:#2475a0}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-vk{border-color:#243549}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-medium{border-color:#00452c}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-quora{border-color:#420e00}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-meetup{border-color:#9b181c}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-goodreads{border-color:#000}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-snapchat{border-color:#999700}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-500px{border-color:#00557f}.saboxplugin-socials.sabox-colored .saboxplugin-icon-color .sab-mastodont{border-color:#185886}.sabox-plus-item{margin-bottom:20px}@media screen and (max-width:480px){.saboxplugin-wrap{text-align:center}.saboxplugin-wrap .saboxplugin-gravatar{float:none;padding:20px 0;text-align:center;margin:0 auto;display:block}.saboxplugin-wrap .saboxplugin-gravatar img{float:none;display:inline-block;display:-moz-inline-stack;vertical-align:middle;zoom:1}.saboxplugin-wrap .saboxplugin-desc{margin:0 10px 20px;text-align:center}.saboxplugin-wrap .saboxplugin-authorname{text-align:center;margin:10px 0 20px}}body .saboxplugin-authorname a,body .saboxplugin-authorname a:hover{box-shadow:none;-webkit-box-shadow:none}a.sab-profile-edit{font-size:16px!important;line-height:1!important}.sab-edit-settings a,a.sab-profile-edit{color:#0073aa!important;box-shadow:none!important;-webkit-box-shadow:none!important}.sab-edit-settings{margin-right:15px;position:absolute;right:0;z-index:2;bottom:10px;line-height:20px}.sab-edit-settings i{margin-left:5px}.saboxplugin-socials{line-height:1!important}.rtl .saboxplugin-wrap .saboxplugin-gravatar{float:right}.rtl .saboxplugin-wrap .saboxplugin-authorname{display:flex;align-items:center}.rtl .saboxplugin-wrap .saboxplugin-authorname .sab-profile-edit{margin-right:10px}.rtl .sab-edit-settings{right:auto;left:0}img.sab-custom-avatar{max-width:75px;}.saboxplugin-wrap .saboxplugin-gravatar img {-webkit-border-radius:50%;-moz-border-radius:50%;-ms-border-radius:50%;-o-border-radius:50%;border-radius:50%;}.saboxplugin-wrap {margin-top:20px; margin-bottom:0px; padding: 0px 0px }.saboxplugin-wrap .saboxplugin-authorname {font-size:16px; line-height:23px;}.saboxplugin-wrap .saboxplugin-desc p, .saboxplugin-wrap .saboxplugin-desc {font-size:13px !important; line-height:20px !important;}.saboxplugin-wrap .saboxplugin-web {font-size:14px;}.saboxplugin-wrap .saboxplugin-socials a svg {width:18px;height:18px;}</style><link rel='stylesheet' id='tve_leads_forms-css'  href='//www.dataquest.io/wp-content/plugins/thrive-leads/editor-layouts/css/frontend.css?ver=2.2.5.2' type='text/css' media='all' />
<script type='text/javascript' src='https://www.dataquest.io/wp-content/plugins/thrive-headline-optimizer/frontend/js/triggers.min.js?ver=1.1.30'></script>
<script type='text/javascript' src='https://www.dataquest.io/wp-includes/js/imagesloaded.min.js?ver=3.2.0'></script>
<script type='text/javascript' src='https://www.dataquest.io/wp-includes/js/masonry.min.js?ver=3.3.2'></script>
<script type='text/javascript' src='https://www.dataquest.io/wp-includes/js/jquery/jquery.masonry.min.js'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var tve_frontend_options = {"ajaxurl":"https:\/\/www.dataquest.io\/wp-admin\/admin-ajax.php","is_editor_page":"","page_events":[],"is_single":"1","social_fb_app_id":"","dash_url":"https:\/\/www.dataquest.io\/wp-content\/plugins\/thrive-visual-editor\/thrive-dashboard","translations":{"Copy":"Copy"},"routes":{"posts":"https:\/\/www.dataquest.io\/wp-json\/tcb\/v1\/posts"},"post_id":"1998"};
/* ]]> */
</script>
<script type='text/javascript' src='https://www.dataquest.io/wp-content/plugins/thrive-visual-editor/editor/js/dist/frontend.min.js?ver=2.4.4.2'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var ThriveApp = {"ajax_url":"https:\/\/www.dataquest.io\/wp-admin\/admin-ajax.php","lazy_load_comments":"1","comments_loaded":"0","translations":{"ProductDetails":"Product Details"}};
/* ]]> */
</script>
<script type='text/javascript' src='https://www.dataquest.io/wp-content/themes/ignition/js/script.min.js?ver=5.2.4'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var tve_dash_front = {"ajaxurl":"https:\/\/www.dataquest.io\/wp-admin\/admin-ajax.php","force_ajax_send":"","is_crawler":""};
/* ]]> */
</script>
<script type='text/javascript' src='https://www.dataquest.io/wp-content/plugins/thrive-visual-editor/thrive-dashboard/js/dist/frontend.min.js?ver=2.2.4.2'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var ThriveApprentice = {"ajax_url":"https:\/\/www.dataquest.io\/wp-admin\/admin-ajax.php","current_post_id":"1998","lang":{"remove_from_fav":"Remove from Favorites","add_to_fav":"Mark as Favorite"},"progress_status":{"new":"new","started":"started","completed":"completed"}};
/* ]]> */
</script>
<script type='text/javascript' src='https://www.dataquest.io/wp-content/themes/ignition/appr/js/thrive-apprentice.js?ver=5.2.4'></script>
<script type='text/javascript'>
/* <![CDATA[ */
var q2w3_sidebar_options = [{"sidebar":"sidebar-1","margin_top":0,"margin_bottom":0,"stop_id":"dq_footer","screen_max_width":500,"screen_max_height":0,"width_inherit":false,"refresh_interval":1500,"window_load_hook":false,"disable_mo_api":false,"widgets":["custom_html-2","search-3","nav_menu-3","nav_menu-10"]}];
/* ]]> */
</script>
<script type='text/javascript' src='https://www.dataquest.io/wp-content/plugins/q2w3-fixed-widget/js/q2w3-fixed-widget.min.js?ver=5.1.9'></script>
<script type='text/javascript' src='https://www.dataquest.io/wp-content/plugins/posts-data-table/assets/js/datatables/datatables.min.js?ver=1.10.18'></script>
<script type='text/javascript' src='https://www.dataquest.io/wp-content/plugins/posts-data-table/assets/js/posts-data-table.min.js?ver=1.2'></script>
<script type='text/javascript' src='https://www.dataquest.io/wp-content/plugins/ank-prism-for-wp/out/prism-js.min.js?ver=1550607458'></script>
<script type='text/javascript' src='https://www.dataquest.io/wp-includes/js/wp-embed.min.js?ver=5.2.4'></script>
<script type='text/javascript' src='//www.dataquest.io/wp-content/plugins/thrive-leads/js/frontend.min.js?ver=2.2.5.2'></script>
<script type="text/javascript">/*<![CDATA[*/var THO_Front = THO_Front || {}; THO_Front.data = {"end_of_content_id":"tho-end-content","is_single":true,"log_url":"https:\/\/www.dataquest.io\/wp-json\/tho\/v1\/logs","active_triggers":{"viewport":"thrive_headline"},"log_engagements":[],"post_id":1998,"test_id":0,"const":{"_e_click":1,"_e_scroll":2,"_e_time":3,"_impression":1,"_engagement":2}}/*]]> */</script><script type="text/javascript">var tcb_post_lists=JSON.parse('[]');</script><script type="text/javascript">/*<![CDATA[*/if ( !window.TL_Const ) {var TL_Const={"security":"87b10fbaab","ajax_url":"https:\/\/www.dataquest.io\/wp-admin\/admin-ajax.php","forms":[],"action_conversion":"tve_leads_ajax_conversion","action_impression":"tve_leads_ajax_impression","ajax_load":1,"main_group_id":17187,"display_options":{"allowed_post_types":[],"flag_url_match":false},"shortcode_ids":["11317"],"custom_post_data":{"http_referrer":"https:\/\/www.google.co.in\/"},"current_screen":{"screen_type":4,"screen_id":1998},"ignored_fields":["email","_captcha_size","_captcha_theme","_captcha_type","_submit_option","_use_captcha","g-recaptcha-response","__tcb_lg_fc","__tcb_lg_msg","_state","_form_type","_error_message_option","_back_url","_submit_option","url","_asset_group","_asset_option","mailchimp_optin"]};} else {ThriveGlobal.$j.extend(true, TL_Const, {"security":"87b10fbaab","ajax_url":"https:\/\/www.dataquest.io\/wp-admin\/admin-ajax.php","forms":[],"action_conversion":"tve_leads_ajax_conversion","action_impression":"tve_leads_ajax_impression","ajax_load":1,"main_group_id":17187,"display_options":{"allowed_post_types":[],"flag_url_match":false},"shortcode_ids":["11317"],"custom_post_data":{"http_referrer":"https:\/\/www.google.co.in\/"},"current_screen":{"screen_type":4,"screen_id":1998},"ignored_fields":["email","_captcha_size","_captcha_theme","_captcha_type","_submit_option","_use_captcha","g-recaptcha-response","__tcb_lg_fc","__tcb_lg_msg","_state","_form_type","_error_message_option","_back_url","_submit_option","url","_asset_group","_asset_option","mailchimp_optin"]})} /*]]> */</script></body>
</html>